{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCOGS 118B Project\\nAuthor: Brian Henriquez, Simon Fong, Wilson Tran\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "COGS 181 Project\n",
    "Author: Brian Henriquez, Simon Fong, Wilson Tran\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib\n",
    "from datetime import datetime                   # Use to record time\n",
    "import json                                     # Writing data to logger\n",
    "matplotlib.use('Agg')                           # Stops from plotting to screen\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import Dataset                     # Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from ../../simon/keras/plankton\n",
      "Split 30336 data into 6067 training, 4550 validation, and 19718 testing data.\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"../../simon/keras/plankton\"\n",
    "IMAGE_WIDTH,IMAGE_HEIGHT,NUM_CHANNELS = 299,299,3\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 50\n",
    "NUM_TRAIN,NUM_VAL,NUM_TEST = 20,15,65\n",
    "\n",
    "\n",
    "ID = \"{}_{}_{}_{}_{}_{}_{}\".format(\"5De256relue\",DATASET_NAME,\n",
    "                                EPOCHS,BATCH_SIZE,NUM_TRAIN,NUM_VAL,NUM_TEST)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "cal = Dataset(DATASET_NAME,IMAGE_HEIGHT,IMAGE_WIDTH)\n",
    "cal.read_data()\n",
    "cal.train_val_test_split(NUM_TRAIN,NUM_VAL,NUM_TEST)\n",
    "num_classes = cal.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"Returns a pretrained model\"\"\"\n",
    "    \n",
    "    # Loads base model\n",
    "    base_model = InceptionV3(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
    "    print(\"Model weights loaded.\")\n",
    "    \n",
    "    base_out = base_model.output\n",
    "\n",
    "    # Add more layers\n",
    "    x = Flatten()(base_out)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    # Additional variation \n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "\n",
    "    # Final fully connected layer to work with our data\n",
    "    predictions = Dense(num_classes,activation='softmax')(x)\n",
    "\n",
    "    # Build a final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    print(\"Model structure\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizers.SGD(lr=1e-4,momentum=0.9),\n",
    "                'categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(\"Model compiled\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logger(message):\n",
    "    \"\"\"Logs any message into a file\"\"\"\n",
    "    with open('../models/stats.txt', 'a+') as f:\n",
    "        print >>f, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Make model\n",
    "    model = load_model()\n",
    "    print(\"Model created\\n\")\n",
    "\n",
    "    # Init data array to plot\n",
    "    train_acc = np.array([])\n",
    "    train_val_acc = np.array([])\n",
    "    train_loss = np.array([])\n",
    "    train_val_loss = np.array([])\n",
    "    \n",
    "    # Load the training data\n",
    "    X_train, Y_train = cal.load_training()\n",
    "    \n",
    "    # Load the validation data\n",
    "    X_val, Y_val = cal.load_validation()\n",
    "    \n",
    "    # Start time\n",
    "    start_time = datetime.now()\n",
    "    print('Start Time', start_time)\n",
    "    \n",
    "    # Train model and store stats in history\n",
    "    history = model.fit(x=X_train,y=Y_train,batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCHS,validation_data=(X_val,Y_val))\n",
    "    \n",
    "    # End time\n",
    "    stop_time = datetime.now()\n",
    "    print('Stop Time', stop_time)\n",
    "    \n",
    "    # Print total time\n",
    "    elapsed_time = stop_time - start_time\n",
    "    print('My Elapsed Time', elapsed_time)\n",
    "    logger(elapsed_time)   \n",
    "\n",
    "    # Append the accuracy and loss scores\n",
    "    train_acc = np.append(train_acc, history.history['acc'])\n",
    "    train_val_acc = np.append(train_val_acc, history.history['val_acc'])\n",
    "    train_loss = np.append(train_loss, history.history['loss'])\n",
    "    train_val_loss = np.append(train_val_loss, history.history['val_loss'])\n",
    "    \n",
    "     \n",
    "    # Save model weights\n",
    "    model.save('../models/{}.h5'.format(ID))\n",
    "    logger(ID)\n",
    "    logger(history.history)\n",
    "    print(\"Model weights saved.\")\n",
    "\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.hold(True)\n",
    "    plt.plot(train_acc, label = \"Train Accuracy\")\n",
    "    plt.plot(train_val_acc, label = \"Validation Accuracy\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig('../plots/acc_vs_val_acc_{}.png'.format(ID))\n",
    "    plt.hold(False)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.hold(True)\n",
    "    plt.plot(train_loss, label = \"Train Loss\")\n",
    "    plt.plot(train_val_loss, label = \"Validation Loss\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig('./plots/loss_vs_val_loss_{}.png'.format(ID))\n",
    "    plt.hold(False)\n",
    "    plt.show()\n",
    "    \n",
    "    # Test the model\n",
    "    X_test, Y_test = cal.load_testing()\n",
    "    metrics = model.evaluate(x=X_test,y=Y_test, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    print(metrics)\n",
    "    logger(metrics)\n",
    "    print(model.metrics_names)\n",
    "    logger(model.metrics_names)\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded.\n",
      "Model structure\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 299, 299, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)               (None, 149, 149, 32)  864         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNor (None, 149, 149, 32)  96          conv2d_95[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, 149, 149, 32)  0           batch_normalization_95[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)               (None, 147, 147, 32)  9216        activation_95[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNor (None, 147, 147, 32)  96          conv2d_96[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, 147, 147, 32)  0           batch_normalization_96[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)               (None, 147, 147, 64)  18432       activation_96[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNor (None, 147, 147, 64)  192         conv2d_97[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, 147, 147, 64)  0           batch_normalization_97[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 73, 73, 64)    0           activation_97[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)               (None, 73, 73, 80)    5120        max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNor (None, 73, 73, 80)    240         conv2d_98[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, 73, 73, 80)    0           batch_normalization_98[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)               (None, 71, 71, 192)   138240      activation_98[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNor (None, 71, 71, 192)   576         conv2d_99[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, 71, 71, 192)   0           batch_normalization_99[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, 35, 35, 192)   0           activation_99[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)              (None, 35, 35, 64)    12288       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchNo (None, 35, 35, 64)    192         conv2d_103[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_103 (Activation)      (None, 35, 35, 64)    0           batch_normalization_103[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)              (None, 35, 35, 48)    9216        max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)              (None, 35, 35, 96)    55296       activation_103[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchNo (None, 35, 35, 48)    144         conv2d_101[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchNo (None, 35, 35, 96)    288         conv2d_104[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, 35, 35, 48)    0           batch_normalization_101[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_104 (Activation)      (None, 35, 35, 96)    0           batch_normalization_104[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePoo (None, 35, 35, 192)   0           max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)              (None, 35, 35, 64)    12288       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)              (None, 35, 35, 64)    76800       activation_101[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)              (None, 35, 35, 96)    82944       activation_104[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)              (None, 35, 35, 32)    6144        average_pooling2d_10[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchNo (None, 35, 35, 64)    192         conv2d_100[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchNo (None, 35, 35, 64)    192         conv2d_102[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchNo (None, 35, 35, 96)    288         conv2d_105[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchNo (None, 35, 35, 32)    96          conv2d_106[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, 35, 35, 64)    0           batch_normalization_100[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, 35, 35, 64)    0           batch_normalization_102[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_105 (Activation)      (None, 35, 35, 96)    0           batch_normalization_105[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_106 (Activation)      (None, 35, 35, 32)    0           batch_normalization_106[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, 35, 35, 256)   0           activation_100[0][0]             \n",
      "                                                                   activation_102[0][0]             \n",
      "                                                                   activation_105[0][0]             \n",
      "                                                                   activation_106[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)              (None, 35, 35, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchNo (None, 35, 35, 64)    192         conv2d_110[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_110 (Activation)      (None, 35, 35, 64)    0           batch_normalization_110[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)              (None, 35, 35, 48)    12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)              (None, 35, 35, 96)    55296       activation_110[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchNo (None, 35, 35, 48)    144         conv2d_108[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchNo (None, 35, 35, 96)    288         conv2d_111[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_108 (Activation)      (None, 35, 35, 48)    0           batch_normalization_108[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_111 (Activation)      (None, 35, 35, 96)    0           batch_normalization_111[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePoo (None, 35, 35, 256)   0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)              (None, 35, 35, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)              (None, 35, 35, 64)    76800       activation_108[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)              (None, 35, 35, 96)    82944       activation_111[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)              (None, 35, 35, 64)    16384       average_pooling2d_11[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchNo (None, 35, 35, 64)    192         conv2d_107[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchNo (None, 35, 35, 64)    192         conv2d_109[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchNo (None, 35, 35, 96)    288         conv2d_112[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchNo (None, 35, 35, 64)    192         conv2d_113[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_107 (Activation)      (None, 35, 35, 64)    0           batch_normalization_107[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_109 (Activation)      (None, 35, 35, 64)    0           batch_normalization_109[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_112 (Activation)      (None, 35, 35, 96)    0           batch_normalization_112[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_113 (Activation)      (None, 35, 35, 64)    0           batch_normalization_113[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, 35, 35, 288)   0           activation_107[0][0]             \n",
      "                                                                   activation_109[0][0]             \n",
      "                                                                   activation_112[0][0]             \n",
      "                                                                   activation_113[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)              (None, 35, 35, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchNo (None, 35, 35, 64)    192         conv2d_117[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_117 (Activation)      (None, 35, 35, 64)    0           batch_normalization_117[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)              (None, 35, 35, 48)    13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)              (None, 35, 35, 96)    55296       activation_117[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchNo (None, 35, 35, 48)    144         conv2d_115[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchNo (None, 35, 35, 96)    288         conv2d_118[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_115 (Activation)      (None, 35, 35, 48)    0           batch_normalization_115[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_118 (Activation)      (None, 35, 35, 96)    0           batch_normalization_118[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePoo (None, 35, 35, 288)   0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)              (None, 35, 35, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)              (None, 35, 35, 64)    76800       activation_115[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)              (None, 35, 35, 96)    82944       activation_118[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)              (None, 35, 35, 64)    18432       average_pooling2d_12[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchNo (None, 35, 35, 64)    192         conv2d_114[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchNo (None, 35, 35, 64)    192         conv2d_116[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchNo (None, 35, 35, 96)    288         conv2d_119[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchNo (None, 35, 35, 64)    192         conv2d_120[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_114 (Activation)      (None, 35, 35, 64)    0           batch_normalization_114[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_116 (Activation)      (None, 35, 35, 64)    0           batch_normalization_116[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_119 (Activation)      (None, 35, 35, 96)    0           batch_normalization_119[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_120 (Activation)      (None, 35, 35, 64)    0           batch_normalization_120[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, 35, 35, 288)   0           activation_114[0][0]             \n",
      "                                                                   activation_116[0][0]             \n",
      "                                                                   activation_119[0][0]             \n",
      "                                                                   activation_120[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)              (None, 35, 35, 64)    18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchNo (None, 35, 35, 64)    192         conv2d_122[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_122 (Activation)      (None, 35, 35, 64)    0           batch_normalization_122[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)              (None, 35, 35, 96)    55296       activation_122[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchNo (None, 35, 35, 96)    288         conv2d_123[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_123 (Activation)      (None, 35, 35, 96)    0           batch_normalization_123[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)              (None, 17, 17, 384)   995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)              (None, 17, 17, 96)    82944       activation_123[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchNo (None, 17, 17, 384)   1152        conv2d_121[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchNo (None, 17, 17, 96)    288         conv2d_124[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_121 (Activation)      (None, 17, 17, 384)   0           batch_normalization_121[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_124 (Activation)      (None, 17, 17, 96)    0           batch_normalization_124[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)   (None, 17, 17, 288)   0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, 17, 17, 768)   0           activation_121[0][0]             \n",
      "                                                                   activation_124[0][0]             \n",
      "                                                                   max_pooling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)              (None, 17, 17, 128)   98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchNo (None, 17, 17, 128)   384         conv2d_129[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, 17, 17, 128)   0           batch_normalization_129[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)              (None, 17, 17, 128)   114688      activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchNo (None, 17, 17, 128)   384         conv2d_130[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, 17, 17, 128)   0           batch_normalization_130[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)              (None, 17, 17, 128)   98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)              (None, 17, 17, 128)   114688      activation_130[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchNo (None, 17, 17, 128)   384         conv2d_126[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchNo (None, 17, 17, 128)   384         conv2d_131[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_126 (Activation)      (None, 17, 17, 128)   0           batch_normalization_126[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, 17, 17, 128)   0           batch_normalization_131[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)              (None, 17, 17, 128)   114688      activation_126[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)              (None, 17, 17, 128)   114688      activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchNo (None, 17, 17, 128)   384         conv2d_127[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchNo (None, 17, 17, 128)   384         conv2d_132[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, 17, 17, 128)   0           batch_normalization_127[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, 17, 17, 128)   0           batch_normalization_132[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePoo (None, 17, 17, 768)   0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)              (None, 17, 17, 192)   147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)              (None, 17, 17, 192)   172032      activation_127[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)              (None, 17, 17, 192)   172032      activation_132[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_13[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchNo (None, 17, 17, 192)   576         conv2d_125[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchNo (None, 17, 17, 192)   576         conv2d_128[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchNo (None, 17, 17, 192)   576         conv2d_133[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchNo (None, 17, 17, 192)   576         conv2d_134[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_125 (Activation)      (None, 17, 17, 192)   0           batch_normalization_125[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, 17, 17, 192)   0           batch_normalization_128[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, 17, 17, 192)   0           batch_normalization_133[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, 17, 17, 192)   0           batch_normalization_134[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, 17, 17, 768)   0           activation_125[0][0]             \n",
      "                                                                   activation_128[0][0]             \n",
      "                                                                   activation_133[0][0]             \n",
      "                                                                   activation_134[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)              (None, 17, 17, 160)   122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchNo (None, 17, 17, 160)   480         conv2d_139[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, 17, 17, 160)   0           batch_normalization_139[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)              (None, 17, 17, 160)   179200      activation_139[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchNo (None, 17, 17, 160)   480         conv2d_140[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, 17, 17, 160)   0           batch_normalization_140[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)              (None, 17, 17, 160)   122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)              (None, 17, 17, 160)   179200      activation_140[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchNo (None, 17, 17, 160)   480         conv2d_136[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchNo (None, 17, 17, 160)   480         conv2d_141[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, 17, 17, 160)   0           batch_normalization_136[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_141 (Activation)      (None, 17, 17, 160)   0           batch_normalization_141[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)              (None, 17, 17, 160)   179200      activation_136[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)              (None, 17, 17, 160)   179200      activation_141[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchNo (None, 17, 17, 160)   480         conv2d_137[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchNo (None, 17, 17, 160)   480         conv2d_142[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, 17, 17, 160)   0           batch_normalization_137[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_142 (Activation)      (None, 17, 17, 160)   0           batch_normalization_142[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePoo (None, 17, 17, 768)   0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)              (None, 17, 17, 192)   147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)              (None, 17, 17, 192)   215040      activation_137[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)              (None, 17, 17, 192)   215040      activation_142[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_14[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchNo (None, 17, 17, 192)   576         conv2d_135[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchNo (None, 17, 17, 192)   576         conv2d_138[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchNo (None, 17, 17, 192)   576         conv2d_143[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchNo (None, 17, 17, 192)   576         conv2d_144[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, 17, 17, 192)   0           batch_normalization_135[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, 17, 17, 192)   0           batch_normalization_138[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, 17, 17, 192)   0           batch_normalization_143[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_144 (Activation)      (None, 17, 17, 192)   0           batch_normalization_144[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, 17, 17, 768)   0           activation_135[0][0]             \n",
      "                                                                   activation_138[0][0]             \n",
      "                                                                   activation_143[0][0]             \n",
      "                                                                   activation_144[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)              (None, 17, 17, 160)   122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchNo (None, 17, 17, 160)   480         conv2d_149[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_149 (Activation)      (None, 17, 17, 160)   0           batch_normalization_149[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)              (None, 17, 17, 160)   179200      activation_149[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchNo (None, 17, 17, 160)   480         conv2d_150[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_150 (Activation)      (None, 17, 17, 160)   0           batch_normalization_150[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)              (None, 17, 17, 160)   122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)              (None, 17, 17, 160)   179200      activation_150[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchNo (None, 17, 17, 160)   480         conv2d_146[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchNo (None, 17, 17, 160)   480         conv2d_151[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_146 (Activation)      (None, 17, 17, 160)   0           batch_normalization_146[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_151 (Activation)      (None, 17, 17, 160)   0           batch_normalization_151[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)              (None, 17, 17, 160)   179200      activation_146[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)              (None, 17, 17, 160)   179200      activation_151[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchNo (None, 17, 17, 160)   480         conv2d_147[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchNo (None, 17, 17, 160)   480         conv2d_152[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_147 (Activation)      (None, 17, 17, 160)   0           batch_normalization_147[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_152 (Activation)      (None, 17, 17, 160)   0           batch_normalization_152[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePoo (None, 17, 17, 768)   0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)              (None, 17, 17, 192)   147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)              (None, 17, 17, 192)   215040      activation_147[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)              (None, 17, 17, 192)   215040      activation_152[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_15[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchNo (None, 17, 17, 192)   576         conv2d_145[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchNo (None, 17, 17, 192)   576         conv2d_148[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchNo (None, 17, 17, 192)   576         conv2d_153[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchNo (None, 17, 17, 192)   576         conv2d_154[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_145 (Activation)      (None, 17, 17, 192)   0           batch_normalization_145[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_148 (Activation)      (None, 17, 17, 192)   0           batch_normalization_148[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_153 (Activation)      (None, 17, 17, 192)   0           batch_normalization_153[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_154 (Activation)      (None, 17, 17, 192)   0           batch_normalization_154[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, 17, 17, 768)   0           activation_145[0][0]             \n",
      "                                                                   activation_148[0][0]             \n",
      "                                                                   activation_153[0][0]             \n",
      "                                                                   activation_154[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)              (None, 17, 17, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchNo (None, 17, 17, 192)   576         conv2d_159[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_159 (Activation)      (None, 17, 17, 192)   0           batch_normalization_159[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)              (None, 17, 17, 192)   258048      activation_159[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchNo (None, 17, 17, 192)   576         conv2d_160[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_160 (Activation)      (None, 17, 17, 192)   0           batch_normalization_160[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)              (None, 17, 17, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)              (None, 17, 17, 192)   258048      activation_160[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchNo (None, 17, 17, 192)   576         conv2d_156[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchNo (None, 17, 17, 192)   576         conv2d_161[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_156 (Activation)      (None, 17, 17, 192)   0           batch_normalization_156[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_161 (Activation)      (None, 17, 17, 192)   0           batch_normalization_161[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)              (None, 17, 17, 192)   258048      activation_156[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)              (None, 17, 17, 192)   258048      activation_161[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchNo (None, 17, 17, 192)   576         conv2d_157[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchNo (None, 17, 17, 192)   576         conv2d_162[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_157 (Activation)      (None, 17, 17, 192)   0           batch_normalization_157[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_162 (Activation)      (None, 17, 17, 192)   0           batch_normalization_162[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePoo (None, 17, 17, 768)   0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)              (None, 17, 17, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)              (None, 17, 17, 192)   258048      activation_157[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)              (None, 17, 17, 192)   258048      activation_162[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_16[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchNo (None, 17, 17, 192)   576         conv2d_155[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchNo (None, 17, 17, 192)   576         conv2d_158[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchNo (None, 17, 17, 192)   576         conv2d_163[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchNo (None, 17, 17, 192)   576         conv2d_164[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_155 (Activation)      (None, 17, 17, 192)   0           batch_normalization_155[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_158 (Activation)      (None, 17, 17, 192)   0           batch_normalization_158[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_163 (Activation)      (None, 17, 17, 192)   0           batch_normalization_163[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_164 (Activation)      (None, 17, 17, 192)   0           batch_normalization_164[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, 17, 17, 768)   0           activation_155[0][0]             \n",
      "                                                                   activation_158[0][0]             \n",
      "                                                                   activation_163[0][0]             \n",
      "                                                                   activation_164[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)              (None, 17, 17, 192)   147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchNo (None, 17, 17, 192)   576         conv2d_167[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_167 (Activation)      (None, 17, 17, 192)   0           batch_normalization_167[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)              (None, 17, 17, 192)   258048      activation_167[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchNo (None, 17, 17, 192)   576         conv2d_168[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_168 (Activation)      (None, 17, 17, 192)   0           batch_normalization_168[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)              (None, 17, 17, 192)   147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)              (None, 17, 17, 192)   258048      activation_168[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchNo (None, 17, 17, 192)   576         conv2d_165[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchNo (None, 17, 17, 192)   576         conv2d_169[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_165 (Activation)      (None, 17, 17, 192)   0           batch_normalization_165[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_169 (Activation)      (None, 17, 17, 192)   0           batch_normalization_169[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)              (None, 8, 8, 320)     552960      activation_165[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)              (None, 8, 8, 192)     331776      activation_169[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchNo (None, 8, 8, 320)     960         conv2d_166[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchNo (None, 8, 8, 192)     576         conv2d_170[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_166 (Activation)      (None, 8, 8, 320)     0           batch_normalization_166[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_170 (Activation)      (None, 8, 8, 192)     0           batch_normalization_170[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)   (None, 8, 8, 768)     0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, 8, 8, 1280)    0           activation_166[0][0]             \n",
      "                                                                   activation_170[0][0]             \n",
      "                                                                   max_pooling2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)              (None, 8, 8, 448)     573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchNo (None, 8, 8, 448)     1344        conv2d_175[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_175 (Activation)      (None, 8, 8, 448)     0           batch_normalization_175[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)              (None, 8, 8, 384)     491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)              (None, 8, 8, 384)     1548288     activation_175[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchNo (None, 8, 8, 384)     1152        conv2d_172[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchNo (None, 8, 8, 384)     1152        conv2d_176[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_172 (Activation)      (None, 8, 8, 384)     0           batch_normalization_172[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_176 (Activation)      (None, 8, 8, 384)     0           batch_normalization_176[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)              (None, 8, 8, 384)     442368      activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)              (None, 8, 8, 384)     442368      activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)              (None, 8, 8, 384)     442368      activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)              (None, 8, 8, 384)     442368      activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePoo (None, 8, 8, 1280)    0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)              (None, 8, 8, 320)     409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchNo (None, 8, 8, 384)     1152        conv2d_173[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchNo (None, 8, 8, 384)     1152        conv2d_174[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchNo (None, 8, 8, 384)     1152        conv2d_177[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchNo (None, 8, 8, 384)     1152        conv2d_178[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)              (None, 8, 8, 192)     245760      average_pooling2d_17[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchNo (None, 8, 8, 320)     960         conv2d_171[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_173 (Activation)      (None, 8, 8, 384)     0           batch_normalization_173[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_174 (Activation)      (None, 8, 8, 384)     0           batch_normalization_174[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_177 (Activation)      (None, 8, 8, 384)     0           batch_normalization_177[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_178 (Activation)      (None, 8, 8, 384)     0           batch_normalization_178[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchNo (None, 8, 8, 192)     576         conv2d_179[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_171 (Activation)      (None, 8, 8, 320)     0           batch_normalization_171[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, 8, 8, 768)     0           activation_173[0][0]             \n",
      "                                                                   activation_174[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 8, 8, 768)     0           activation_177[0][0]             \n",
      "                                                                   activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_179 (Activation)      (None, 8, 8, 192)     0           batch_normalization_179[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, 8, 8, 2048)    0           activation_171[0][0]             \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_3[0][0]              \n",
      "                                                                   activation_179[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)              (None, 8, 8, 448)     917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchNo (None, 8, 8, 448)     1344        conv2d_184[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_184 (Activation)      (None, 8, 8, 448)     0           batch_normalization_184[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)              (None, 8, 8, 384)     786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)              (None, 8, 8, 384)     1548288     activation_184[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchNo (None, 8, 8, 384)     1152        conv2d_181[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchNo (None, 8, 8, 384)     1152        conv2d_185[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_181 (Activation)      (None, 8, 8, 384)     0           batch_normalization_181[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_185 (Activation)      (None, 8, 8, 384)     0           batch_normalization_185[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)              (None, 8, 8, 384)     442368      activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)              (None, 8, 8, 384)     442368      activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)              (None, 8, 8, 384)     442368      activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)              (None, 8, 8, 384)     442368      activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePoo (None, 8, 8, 2048)    0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)              (None, 8, 8, 320)     655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchNo (None, 8, 8, 384)     1152        conv2d_182[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchNo (None, 8, 8, 384)     1152        conv2d_183[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchNo (None, 8, 8, 384)     1152        conv2d_186[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchNo (None, 8, 8, 384)     1152        conv2d_187[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)              (None, 8, 8, 192)     393216      average_pooling2d_18[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchNo (None, 8, 8, 320)     960         conv2d_180[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_182 (Activation)      (None, 8, 8, 384)     0           batch_normalization_182[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_183 (Activation)      (None, 8, 8, 384)     0           batch_normalization_183[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_186 (Activation)      (None, 8, 8, 384)     0           batch_normalization_186[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_187 (Activation)      (None, 8, 8, 384)     0           batch_normalization_187[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchNo (None, 8, 8, 192)     576         conv2d_188[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_180 (Activation)      (None, 8, 8, 320)     0           batch_normalization_180[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, 8, 8, 768)     0           activation_182[0][0]             \n",
      "                                                                   activation_183[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 8, 8, 768)     0           activation_186[0][0]             \n",
      "                                                                   activation_187[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_188 (Activation)      (None, 8, 8, 192)     0           batch_normalization_188[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, 8, 8, 2048)    0           activation_180[0][0]             \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_4[0][0]              \n",
      "                                                                   activation_188[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 131072)        0           mixed10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 256)           33554688    flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 256)           0           dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 256)           65792       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 256)           65792       dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 256)           65792       dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 256)           65792       dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 256)           65792       dense_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 121)           31097       dense_13[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 55,717,529\n",
      "Trainable params: 55,683,097\n",
      "Non-trainable params: 34,432\n",
      "____________________________________________________________________________________________________\n",
      "Model compiled\n",
      "Model created\n",
      "\n",
      "Loading training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data 6067/6067   \n",
      "Loading validation data...\n",
      "Loaded validation data550/4550   \n",
      "('Start Time', datetime.datetime(2017, 12, 12, 17, 56, 20, 178551))\n",
      "Train on 6067 samples, validate on 4550 samples\n",
      "Epoch 1/100\n",
      "6067/6067 [==============================] - 102s - loss: 4.8059 - acc: 0.0277 - val_loss: 4.7698 - val_acc: 0.0411\n",
      "Epoch 2/100\n",
      "6067/6067 [==============================] - 93s - loss: 4.7041 - acc: 0.0672 - val_loss: 4.6686 - val_acc: 0.0855\n",
      "Epoch 3/100\n",
      "6067/6067 [==============================] - 92s - loss: 4.4671 - acc: 0.0814 - val_loss: 4.6226 - val_acc: 0.0382\n",
      "Epoch 4/100\n",
      "6067/6067 [==============================] - 92s - loss: 4.2716 - acc: 0.1038 - val_loss: 4.4801 - val_acc: 0.0686\n",
      "Epoch 5/100\n",
      "6067/6067 [==============================] - 92s - loss: 4.0983 - acc: 0.1396 - val_loss: 4.2909 - val_acc: 0.1046\n",
      "Epoch 6/100\n",
      "6067/6067 [==============================] - 92s - loss: 3.9380 - acc: 0.1567 - val_loss: 3.9467 - val_acc: 0.1429\n",
      "Epoch 7/100\n",
      "6067/6067 [==============================] - 92s - loss: 3.7670 - acc: 0.1792 - val_loss: 3.6569 - val_acc: 0.2123\n",
      "Epoch 8/100\n",
      "6067/6067 [==============================] - 92s - loss: 3.5884 - acc: 0.2062 - val_loss: 3.6079 - val_acc: 0.2191\n",
      "Epoch 9/100\n",
      "6067/6067 [==============================] - 92s - loss: 3.3982 - acc: 0.2393 - val_loss: 3.5979 - val_acc: 0.2325\n",
      "Epoch 10/100\n",
      "6067/6067 [==============================] - 93s - loss: 3.2334 - acc: 0.2669 - val_loss: 3.1237 - val_acc: 0.3341\n",
      "Epoch 11/100\n",
      "6067/6067 [==============================] - 93s - loss: 3.0792 - acc: 0.2940 - val_loss: 2.9346 - val_acc: 0.3420\n",
      "Epoch 12/100\n",
      "6067/6067 [==============================] - 93s - loss: 2.9302 - acc: 0.3297 - val_loss: 3.2449 - val_acc: 0.3237\n",
      "Epoch 13/100\n",
      "6067/6067 [==============================] - 92s - loss: 2.8012 - acc: 0.3601 - val_loss: 2.7323 - val_acc: 0.4163\n",
      "Epoch 14/100\n",
      "6067/6067 [==============================] - 91s - loss: 2.6781 - acc: 0.3854 - val_loss: 2.7523 - val_acc: 0.4156\n",
      "Epoch 15/100\n",
      "6067/6067 [==============================] - 91s - loss: 2.5530 - acc: 0.4093 - val_loss: 2.4795 - val_acc: 0.4532\n",
      "Epoch 16/100\n",
      "6067/6067 [==============================] - 92s - loss: 2.4206 - acc: 0.4374 - val_loss: 2.5700 - val_acc: 0.4470\n",
      "Epoch 17/100\n",
      "6067/6067 [==============================] - 92s - loss: 2.3054 - acc: 0.4671 - val_loss: 2.5413 - val_acc: 0.4470\n",
      "Epoch 18/100\n",
      "6067/6067 [==============================] - 92s - loss: 2.1928 - acc: 0.4856 - val_loss: 2.4918 - val_acc: 0.4360\n",
      "Epoch 19/100\n",
      "6067/6067 [==============================] - 92s - loss: 2.0843 - acc: 0.5006 - val_loss: 2.1685 - val_acc: 0.5022\n",
      "Epoch 20/100\n",
      "6067/6067 [==============================] - 92s - loss: 1.9938 - acc: 0.5143 - val_loss: 2.1014 - val_acc: 0.5086\n",
      "Epoch 21/100\n",
      "6067/6067 [==============================] - 92s - loss: 1.9067 - acc: 0.5278 - val_loss: 2.2432 - val_acc: 0.4798\n",
      "Epoch 22/100\n",
      "6067/6067 [==============================] - 92s - loss: 1.8225 - acc: 0.5497 - val_loss: 2.0417 - val_acc: 0.5165\n",
      "Epoch 23/100\n",
      "6067/6067 [==============================] - 92s - loss: 1.7261 - acc: 0.5685 - val_loss: 1.9791 - val_acc: 0.5356\n",
      "Epoch 24/100\n",
      "6067/6067 [==============================] - 91s - loss: 1.6546 - acc: 0.5815 - val_loss: 1.9428 - val_acc: 0.5470\n",
      "Epoch 25/100\n",
      "6067/6067 [==============================] - 91s - loss: 1.5752 - acc: 0.6005 - val_loss: 1.9471 - val_acc: 0.5492\n",
      "Epoch 26/100\n",
      "6067/6067 [==============================] - 91s - loss: 1.4831 - acc: 0.6216 - val_loss: 1.9160 - val_acc: 0.5477\n",
      "Epoch 27/100\n",
      "6067/6067 [==============================] - 90s - loss: 1.4032 - acc: 0.6356 - val_loss: 1.8943 - val_acc: 0.5580\n",
      "Epoch 28/100\n",
      "6067/6067 [==============================] - 90s - loss: 1.3460 - acc: 0.6537 - val_loss: 1.8349 - val_acc: 0.5776\n",
      "Epoch 29/100\n",
      "6067/6067 [==============================] - 90s - loss: 1.2778 - acc: 0.6699 - val_loss: 1.8780 - val_acc: 0.5688\n",
      "Epoch 30/100\n",
      "6067/6067 [==============================] - 90s - loss: 1.2059 - acc: 0.6847 - val_loss: 1.8793 - val_acc: 0.5699\n",
      "Epoch 31/100\n",
      "6067/6067 [==============================] - 91s - loss: 1.1401 - acc: 0.6974 - val_loss: 1.9154 - val_acc: 0.5673\n",
      "Epoch 32/100\n",
      "6067/6067 [==============================] - 91s - loss: 1.0828 - acc: 0.7149 - val_loss: 1.8768 - val_acc: 0.5855\n",
      "Epoch 33/100\n",
      "6067/6067 [==============================] - 90s - loss: 1.0261 - acc: 0.7267 - val_loss: 1.8292 - val_acc: 0.5912\n",
      "Epoch 34/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.9589 - acc: 0.7457 - val_loss: 1.8193 - val_acc: 0.5947\n",
      "Epoch 35/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.9005 - acc: 0.7597 - val_loss: 1.9223 - val_acc: 0.5723\n",
      "Epoch 36/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.8574 - acc: 0.7704 - val_loss: 1.8979 - val_acc: 0.5875\n",
      "Epoch 37/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.7989 - acc: 0.7882 - val_loss: 1.8028 - val_acc: 0.6035\n",
      "Epoch 38/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.7485 - acc: 0.8039 - val_loss: 1.8980 - val_acc: 0.5978\n",
      "Epoch 39/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.7015 - acc: 0.8192 - val_loss: 1.8437 - val_acc: 0.6077\n",
      "Epoch 40/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.6565 - acc: 0.8266 - val_loss: 1.9719 - val_acc: 0.6046\n",
      "Epoch 41/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.6195 - acc: 0.8385 - val_loss: 1.9147 - val_acc: 0.6171\n",
      "Epoch 42/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.5783 - acc: 0.8489 - val_loss: 1.8833 - val_acc: 0.6130\n",
      "Epoch 43/100\n",
      "6067/6067 [==============================] - 92s - loss: 0.5514 - acc: 0.8523 - val_loss: 1.9933 - val_acc: 0.6088\n",
      "Epoch 44/100\n",
      "6067/6067 [==============================] - 92s - loss: 0.5103 - acc: 0.8655 - val_loss: 1.9231 - val_acc: 0.6193\n",
      "Epoch 45/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.4841 - acc: 0.8708 - val_loss: 1.9987 - val_acc: 0.6079\n",
      "Epoch 46/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.4408 - acc: 0.8821 - val_loss: 1.9988 - val_acc: 0.6178\n",
      "Epoch 47/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.4124 - acc: 0.8922 - val_loss: 2.0539 - val_acc: 0.6116\n",
      "Epoch 48/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.3810 - acc: 0.9003 - val_loss: 2.0391 - val_acc: 0.6207\n",
      "Epoch 49/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.3623 - acc: 0.9064 - val_loss: 2.0834 - val_acc: 0.6105\n",
      "Epoch 50/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.3472 - acc: 0.9123 - val_loss: 2.1774 - val_acc: 0.6079\n",
      "Epoch 51/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.3213 - acc: 0.9201 - val_loss: 2.1990 - val_acc: 0.6004\n",
      "Epoch 52/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.3015 - acc: 0.9222 - val_loss: 2.1359 - val_acc: 0.6235\n",
      "Epoch 53/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.2815 - acc: 0.9273 - val_loss: 2.1987 - val_acc: 0.6015\n",
      "Epoch 54/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.2623 - acc: 0.9332 - val_loss: 2.1491 - val_acc: 0.6277\n",
      "Epoch 55/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.2592 - acc: 0.9334 - val_loss: 2.1553 - val_acc: 0.6251\n",
      "Epoch 56/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.2393 - acc: 0.9367 - val_loss: 2.2137 - val_acc: 0.6176\n",
      "Epoch 57/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.2315 - acc: 0.9400 - val_loss: 2.2026 - val_acc: 0.6277\n",
      "Epoch 58/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.1892 - acc: 0.9575 - val_loss: 2.2683 - val_acc: 0.6196\n",
      "Epoch 59/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.2008 - acc: 0.9515 - val_loss: 2.2062 - val_acc: 0.6336\n",
      "Epoch 60/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.1859 - acc: 0.9534 - val_loss: 2.2986 - val_acc: 0.6281\n",
      "Epoch 61/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.1775 - acc: 0.9567 - val_loss: 2.3993 - val_acc: 0.5996\n",
      "Epoch 62/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.1701 - acc: 0.9570 - val_loss: 2.2393 - val_acc: 0.6275\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6067/6067 [==============================] - 90s - loss: 0.1567 - acc: 0.9618 - val_loss: 2.2508 - val_acc: 0.6268\n",
      "Epoch 64/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.1511 - acc: 0.9646 - val_loss: 2.3665 - val_acc: 0.6189\n",
      "Epoch 65/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.1344 - acc: 0.9710 - val_loss: 2.4542 - val_acc: 0.6138\n",
      "Epoch 66/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.1430 - acc: 0.9646 - val_loss: 2.3306 - val_acc: 0.6334\n",
      "Epoch 67/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.1339 - acc: 0.9700 - val_loss: 2.3765 - val_acc: 0.6303\n",
      "Epoch 68/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.1228 - acc: 0.9721 - val_loss: 2.3368 - val_acc: 0.6251\n",
      "Epoch 69/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.1212 - acc: 0.9730 - val_loss: 2.6140 - val_acc: 0.5989\n",
      "Epoch 70/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.1199 - acc: 0.9695 - val_loss: 2.4358 - val_acc: 0.6246\n",
      "Epoch 71/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.1152 - acc: 0.9726 - val_loss: 2.3565 - val_acc: 0.6365\n",
      "Epoch 72/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.1047 - acc: 0.9773 - val_loss: 2.3802 - val_acc: 0.6253\n",
      "Epoch 73/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.0967 - acc: 0.9782 - val_loss: 2.4074 - val_acc: 0.6400\n",
      "Epoch 74/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.0912 - acc: 0.9801 - val_loss: 2.3946 - val_acc: 0.6402\n",
      "Epoch 75/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.0917 - acc: 0.9786 - val_loss: 2.4795 - val_acc: 0.6292\n",
      "Epoch 76/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.0878 - acc: 0.9799 - val_loss: 2.3935 - val_acc: 0.6360\n",
      "Epoch 77/100\n",
      "6067/6067 [==============================] - 90s - loss: 0.0871 - acc: 0.9789 - val_loss: 2.4898 - val_acc: 0.6303\n",
      "Epoch 78/100\n",
      "6067/6067 [==============================] - 92s - loss: 0.0782 - acc: 0.9819 - val_loss: 2.5721 - val_acc: 0.6119\n",
      "Epoch 79/100\n",
      "6067/6067 [==============================] - 93s - loss: 0.0784 - acc: 0.9842 - val_loss: 2.6872 - val_acc: 0.6059\n",
      "Epoch 80/100\n",
      "6067/6067 [==============================] - 92s - loss: 0.0736 - acc: 0.9847 - val_loss: 2.4657 - val_acc: 0.6391\n",
      "Epoch 81/100\n",
      "6067/6067 [==============================] - 93s - loss: 0.0756 - acc: 0.9825 - val_loss: 2.6272 - val_acc: 0.6257\n",
      "Epoch 82/100\n",
      "6067/6067 [==============================] - 92s - loss: 0.0724 - acc: 0.9834 - val_loss: 2.5131 - val_acc: 0.6330\n",
      "Epoch 83/100\n",
      "6067/6067 [==============================] - 91s - loss: 0.0709 - acc: 0.9827 - val_loss: 2.5501 - val_acc: 0.6341\n",
      "Epoch 84/100\n",
      "2700/6067 [============>.................] - ETA: 39s - loss: 0.0614 - acc: 0.9867"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
