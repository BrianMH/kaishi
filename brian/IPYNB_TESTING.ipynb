{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import native modules\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime                    # Use to record time\n",
    "\n",
    "# Import Keras functions\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation, concatenate,\\\n",
    "                GlobalAveragePooling2D, Conv2D, Concatenate, AveragePooling2D, BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as backK\n",
    "\n",
    "# Import matrix and plotting\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')                           # Stops from plotting to screen\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import OpenCV\n",
    "import cv2\n",
    "\n",
    "# Import custom dataset class\n",
    "from dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from plankton_resized\n",
      "Split 30336 data into 3033 training, 1516 validation, and 25785 testing data.\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = 'plankton_resized'\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 50\n",
    "NUM_TRAIN,NUM_VAL,NUM_TEST = 10,5,85\n",
    "\n",
    "IMAGE_WIDTH,IMAGE_HEIGHT,NUM_CHANNELS = 299,299,3\n",
    "\n",
    "\n",
    "ID = \"{}_{}_{}_{}_{}_{}_{}\".format(\"INCEPTION-AVG-1024relu_EX\",DATASET_NAME,\n",
    "                                EPOCHS,BATCH_SIZE,NUM_TRAIN,NUM_VAL,NUM_TEST)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "cal = Dataset(DATASET_NAME,IMAGE_HEIGHT,IMAGE_WIDTH,resized=True)\n",
    "cal.read_data()\n",
    "cal.train_val_test_split(NUM_TRAIN,NUM_VAL,NUM_TEST)\n",
    "num_classes = cal.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logger(message):\n",
    "    \"\"\"Logs any message into a file\"\"\"\n",
    "    with open('./models/stats.txt', 'a+') as f:\n",
    "        print >>f, message\n",
    "        print(message)\n",
    "\n",
    "def plot(datas, title, xlabel, ylabel, file_name):\n",
    "    \"\"\"Plots the data\"\"\"\n",
    "    plt.figure()\n",
    "    for key,value in datas.iteritems():\n",
    "        plt.plot(value, label=key)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    plots_dir = 'plots'\n",
    "    file_name + '.png'\n",
    "    plot_path = os.path.join(plots_dir,file_name)    \n",
    "    plt.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from inception_v3.py in the keras repository\n",
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), name=None):\n",
    "    \"\"\"Utility function to apply conv + BN (Batch Normalization).\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: filters in `Conv2D`.\n",
    "        num_row: height of the convolution kernel.\n",
    "        num_col: width of the convolution kernel.\n",
    "        padding: padding mode in `Conv2D`.\n",
    "        strides: strides in `Conv2D`.\n",
    "        name: name of the ops; will become `name + '_conv'`\n",
    "            for the convolution and `name + '_bn'` for the\n",
    "            batch norm layer.\n",
    "    # Returns\n",
    "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
    "    \"\"\"\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    if backK.image_data_format() == 'channels_first':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False, name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    x = Activation('relu', name=name)(x)\n",
    "    return x\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Returns a pretrained model\"\"\"\n",
    "    \n",
    "    # Loads base model\n",
    "    base_model = InceptionV3(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
    "    print(\"Model weights loaded.\")\n",
    "    \n",
    "    # Typical Output\n",
    "    x = base_model.output\n",
    "    \n",
    "    # For evaluating pre-inception layers\n",
    "    #x = base_model.layers[-32].output  # \"-1\"st layer\n",
    "    #x = base_model.layers[-63].output  # \"-2\"nd layer\n",
    "\n",
    "    # Inception modules\n",
    "    inception_count = 0          # number of inception layers to add\n",
    "    for i in range(inception_count):\n",
    "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
    "\n",
    "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
    "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
    "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
    "        branch3x3 = concatenate([branch3x3_1, branch3x3_2], axis=3, name='mixed11_'+str(i)+'_added')\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
    "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
    "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
    "        branch3x3dbl = concatenate([branch3x3dbl_1, branch3x3dbl_2], axis=3)\n",
    "\n",
    "        branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = concatenate([branch1x1, branch3x3, branch3x3dbl, branch_pool], axis=3, name='mixed'+str(12+i)+'_added')\n",
    "        \n",
    "    # Add layers (the typical ones)\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(1024,activation='relu')(x)\n",
    "\n",
    "    # Final fully connected layer to work with our data\n",
    "    predictions = Dense(num_classes,activation='softmax')(x)\n",
    "\n",
    "    # Build a final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    print(\"Model structure\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizers.SGD(lr=1e-4,momentum=0.9),\n",
    "                'categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(\"Model compiled\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "INCEPTION-AVG-1024relu_EX_plankton_resized_100_50_10_5_85\n",
      "Inception V3 - +0 inception + 1024 dense (extended) output\n",
      "Model weights loaded.\n",
      "Model structure\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 299, 299, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)              (None, 149, 149, 32)  864         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchNo (None, 149, 149, 32)  96          conv2d_113[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_113 (Activation)      (None, 149, 149, 32)  0           batch_normalization_113[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)              (None, 147, 147, 32)  9216        activation_113[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchNo (None, 147, 147, 32)  96          conv2d_114[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_114 (Activation)      (None, 147, 147, 32)  0           batch_normalization_114[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)              (None, 147, 147, 64)  18432       activation_114[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchNo (None, 147, 147, 64)  192         conv2d_115[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_115 (Activation)      (None, 147, 147, 64)  0           batch_normalization_115[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 73, 73, 64)    0           activation_115[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)              (None, 73, 73, 80)    5120        max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchNo (None, 73, 73, 80)    240         conv2d_116[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_116 (Activation)      (None, 73, 73, 80)    0           batch_normalization_116[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)              (None, 71, 71, 192)   138240      activation_116[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchNo (None, 71, 71, 192)   576         conv2d_117[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_117 (Activation)      (None, 71, 71, 192)   0           batch_normalization_117[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, 35, 35, 192)   0           activation_117[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)              (None, 35, 35, 64)    12288       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchNo (None, 35, 35, 64)    192         conv2d_121[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_121 (Activation)      (None, 35, 35, 64)    0           batch_normalization_121[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)              (None, 35, 35, 48)    9216        max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)              (None, 35, 35, 96)    55296       activation_121[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchNo (None, 35, 35, 48)    144         conv2d_119[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchNo (None, 35, 35, 96)    288         conv2d_122[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_119 (Activation)      (None, 35, 35, 48)    0           batch_normalization_119[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_122 (Activation)      (None, 35, 35, 96)    0           batch_normalization_122[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePoo (None, 35, 35, 192)   0           max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)              (None, 35, 35, 64)    12288       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)              (None, 35, 35, 64)    76800       activation_119[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)              (None, 35, 35, 96)    82944       activation_122[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)              (None, 35, 35, 32)    6144        average_pooling2d_12[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchNo (None, 35, 35, 64)    192         conv2d_118[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchNo (None, 35, 35, 64)    192         conv2d_120[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchNo (None, 35, 35, 96)    288         conv2d_123[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchNo (None, 35, 35, 32)    96          conv2d_124[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_118 (Activation)      (None, 35, 35, 64)    0           batch_normalization_118[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_120 (Activation)      (None, 35, 35, 64)    0           batch_normalization_120[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_123 (Activation)      (None, 35, 35, 96)    0           batch_normalization_123[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_124 (Activation)      (None, 35, 35, 32)    0           batch_normalization_124[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, 35, 35, 256)   0           activation_118[0][0]             \n",
      "                                                                   activation_120[0][0]             \n",
      "                                                                   activation_123[0][0]             \n",
      "                                                                   activation_124[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)              (None, 35, 35, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchNo (None, 35, 35, 64)    192         conv2d_128[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, 35, 35, 64)    0           batch_normalization_128[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)              (None, 35, 35, 48)    12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)              (None, 35, 35, 96)    55296       activation_128[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchNo (None, 35, 35, 48)    144         conv2d_126[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchNo (None, 35, 35, 96)    288         conv2d_129[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_126 (Activation)      (None, 35, 35, 48)    0           batch_normalization_126[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, 35, 35, 96)    0           batch_normalization_129[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePoo (None, 35, 35, 256)   0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)              (None, 35, 35, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)              (None, 35, 35, 64)    76800       activation_126[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)              (None, 35, 35, 96)    82944       activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)              (None, 35, 35, 64)    16384       average_pooling2d_13[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchNo (None, 35, 35, 64)    192         conv2d_125[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchNo (None, 35, 35, 64)    192         conv2d_127[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchNo (None, 35, 35, 96)    288         conv2d_130[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchNo (None, 35, 35, 64)    192         conv2d_131[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_125 (Activation)      (None, 35, 35, 64)    0           batch_normalization_125[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, 35, 35, 64)    0           batch_normalization_127[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, 35, 35, 96)    0           batch_normalization_130[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, 35, 35, 64)    0           batch_normalization_131[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, 35, 35, 288)   0           activation_125[0][0]             \n",
      "                                                                   activation_127[0][0]             \n",
      "                                                                   activation_130[0][0]             \n",
      "                                                                   activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)              (None, 35, 35, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchNo (None, 35, 35, 64)    192         conv2d_135[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, 35, 35, 64)    0           batch_normalization_135[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)              (None, 35, 35, 48)    13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)              (None, 35, 35, 96)    55296       activation_135[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchNo (None, 35, 35, 48)    144         conv2d_133[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchNo (None, 35, 35, 96)    288         conv2d_136[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, 35, 35, 48)    0           batch_normalization_133[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, 35, 35, 96)    0           batch_normalization_136[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePoo (None, 35, 35, 288)   0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)              (None, 35, 35, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)              (None, 35, 35, 64)    76800       activation_133[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)              (None, 35, 35, 96)    82944       activation_136[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)              (None, 35, 35, 64)    18432       average_pooling2d_14[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchNo (None, 35, 35, 64)    192         conv2d_132[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchNo (None, 35, 35, 64)    192         conv2d_134[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchNo (None, 35, 35, 96)    288         conv2d_137[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchNo (None, 35, 35, 64)    192         conv2d_138[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, 35, 35, 64)    0           batch_normalization_132[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, 35, 35, 64)    0           batch_normalization_134[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, 35, 35, 96)    0           batch_normalization_137[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, 35, 35, 64)    0           batch_normalization_138[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, 35, 35, 288)   0           activation_132[0][0]             \n",
      "                                                                   activation_134[0][0]             \n",
      "                                                                   activation_137[0][0]             \n",
      "                                                                   activation_138[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)              (None, 35, 35, 64)    18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchNo (None, 35, 35, 64)    192         conv2d_140[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, 35, 35, 64)    0           batch_normalization_140[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)              (None, 35, 35, 96)    55296       activation_140[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchNo (None, 35, 35, 96)    288         conv2d_141[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_141 (Activation)      (None, 35, 35, 96)    0           batch_normalization_141[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)              (None, 17, 17, 384)   995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)              (None, 17, 17, 96)    82944       activation_141[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchNo (None, 17, 17, 384)   1152        conv2d_139[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchNo (None, 17, 17, 96)    288         conv2d_142[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, 17, 17, 384)   0           batch_normalization_139[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_142 (Activation)      (None, 17, 17, 96)    0           batch_normalization_142[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)   (None, 17, 17, 288)   0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, 17, 17, 768)   0           activation_139[0][0]             \n",
      "                                                                   activation_142[0][0]             \n",
      "                                                                   max_pooling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)              (None, 17, 17, 128)   98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchNo (None, 17, 17, 128)   384         conv2d_147[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_147 (Activation)      (None, 17, 17, 128)   0           batch_normalization_147[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)              (None, 17, 17, 128)   114688      activation_147[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchNo (None, 17, 17, 128)   384         conv2d_148[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_148 (Activation)      (None, 17, 17, 128)   0           batch_normalization_148[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)              (None, 17, 17, 128)   98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)              (None, 17, 17, 128)   114688      activation_148[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchNo (None, 17, 17, 128)   384         conv2d_144[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchNo (None, 17, 17, 128)   384         conv2d_149[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_144 (Activation)      (None, 17, 17, 128)   0           batch_normalization_144[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_149 (Activation)      (None, 17, 17, 128)   0           batch_normalization_149[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)              (None, 17, 17, 128)   114688      activation_144[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)              (None, 17, 17, 128)   114688      activation_149[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchNo (None, 17, 17, 128)   384         conv2d_145[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchNo (None, 17, 17, 128)   384         conv2d_150[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_145 (Activation)      (None, 17, 17, 128)   0           batch_normalization_145[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_150 (Activation)      (None, 17, 17, 128)   0           batch_normalization_150[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePoo (None, 17, 17, 768)   0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)              (None, 17, 17, 192)   147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)              (None, 17, 17, 192)   172032      activation_145[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)              (None, 17, 17, 192)   172032      activation_150[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_15[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchNo (None, 17, 17, 192)   576         conv2d_143[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchNo (None, 17, 17, 192)   576         conv2d_146[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchNo (None, 17, 17, 192)   576         conv2d_151[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchNo (None, 17, 17, 192)   576         conv2d_152[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, 17, 17, 192)   0           batch_normalization_143[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_146 (Activation)      (None, 17, 17, 192)   0           batch_normalization_146[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_151 (Activation)      (None, 17, 17, 192)   0           batch_normalization_151[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_152 (Activation)      (None, 17, 17, 192)   0           batch_normalization_152[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, 17, 17, 768)   0           activation_143[0][0]             \n",
      "                                                                   activation_146[0][0]             \n",
      "                                                                   activation_151[0][0]             \n",
      "                                                                   activation_152[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)              (None, 17, 17, 160)   122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchNo (None, 17, 17, 160)   480         conv2d_157[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_157 (Activation)      (None, 17, 17, 160)   0           batch_normalization_157[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)              (None, 17, 17, 160)   179200      activation_157[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchNo (None, 17, 17, 160)   480         conv2d_158[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_158 (Activation)      (None, 17, 17, 160)   0           batch_normalization_158[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)              (None, 17, 17, 160)   122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)              (None, 17, 17, 160)   179200      activation_158[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchNo (None, 17, 17, 160)   480         conv2d_154[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchNo (None, 17, 17, 160)   480         conv2d_159[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_154 (Activation)      (None, 17, 17, 160)   0           batch_normalization_154[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_159 (Activation)      (None, 17, 17, 160)   0           batch_normalization_159[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)              (None, 17, 17, 160)   179200      activation_154[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)              (None, 17, 17, 160)   179200      activation_159[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchNo (None, 17, 17, 160)   480         conv2d_155[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchNo (None, 17, 17, 160)   480         conv2d_160[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_155 (Activation)      (None, 17, 17, 160)   0           batch_normalization_155[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_160 (Activation)      (None, 17, 17, 160)   0           batch_normalization_160[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePoo (None, 17, 17, 768)   0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)              (None, 17, 17, 192)   147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)              (None, 17, 17, 192)   215040      activation_155[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)              (None, 17, 17, 192)   215040      activation_160[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_16[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchNo (None, 17, 17, 192)   576         conv2d_153[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchNo (None, 17, 17, 192)   576         conv2d_156[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchNo (None, 17, 17, 192)   576         conv2d_161[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchNo (None, 17, 17, 192)   576         conv2d_162[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_153 (Activation)      (None, 17, 17, 192)   0           batch_normalization_153[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_156 (Activation)      (None, 17, 17, 192)   0           batch_normalization_156[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_161 (Activation)      (None, 17, 17, 192)   0           batch_normalization_161[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_162 (Activation)      (None, 17, 17, 192)   0           batch_normalization_162[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, 17, 17, 768)   0           activation_153[0][0]             \n",
      "                                                                   activation_156[0][0]             \n",
      "                                                                   activation_161[0][0]             \n",
      "                                                                   activation_162[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)              (None, 17, 17, 160)   122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchNo (None, 17, 17, 160)   480         conv2d_167[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_167 (Activation)      (None, 17, 17, 160)   0           batch_normalization_167[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)              (None, 17, 17, 160)   179200      activation_167[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchNo (None, 17, 17, 160)   480         conv2d_168[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_168 (Activation)      (None, 17, 17, 160)   0           batch_normalization_168[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)              (None, 17, 17, 160)   122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)              (None, 17, 17, 160)   179200      activation_168[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchNo (None, 17, 17, 160)   480         conv2d_164[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchNo (None, 17, 17, 160)   480         conv2d_169[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_164 (Activation)      (None, 17, 17, 160)   0           batch_normalization_164[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_169 (Activation)      (None, 17, 17, 160)   0           batch_normalization_169[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)              (None, 17, 17, 160)   179200      activation_164[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)              (None, 17, 17, 160)   179200      activation_169[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchNo (None, 17, 17, 160)   480         conv2d_165[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchNo (None, 17, 17, 160)   480         conv2d_170[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_165 (Activation)      (None, 17, 17, 160)   0           batch_normalization_165[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_170 (Activation)      (None, 17, 17, 160)   0           batch_normalization_170[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePoo (None, 17, 17, 768)   0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)              (None, 17, 17, 192)   147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)              (None, 17, 17, 192)   215040      activation_165[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)              (None, 17, 17, 192)   215040      activation_170[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_17[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchNo (None, 17, 17, 192)   576         conv2d_163[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchNo (None, 17, 17, 192)   576         conv2d_166[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchNo (None, 17, 17, 192)   576         conv2d_171[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchNo (None, 17, 17, 192)   576         conv2d_172[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_163 (Activation)      (None, 17, 17, 192)   0           batch_normalization_163[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_166 (Activation)      (None, 17, 17, 192)   0           batch_normalization_166[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_171 (Activation)      (None, 17, 17, 192)   0           batch_normalization_171[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_172 (Activation)      (None, 17, 17, 192)   0           batch_normalization_172[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, 17, 17, 768)   0           activation_163[0][0]             \n",
      "                                                                   activation_166[0][0]             \n",
      "                                                                   activation_171[0][0]             \n",
      "                                                                   activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)              (None, 17, 17, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchNo (None, 17, 17, 192)   576         conv2d_177[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_177 (Activation)      (None, 17, 17, 192)   0           batch_normalization_177[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)              (None, 17, 17, 192)   258048      activation_177[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchNo (None, 17, 17, 192)   576         conv2d_178[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_178 (Activation)      (None, 17, 17, 192)   0           batch_normalization_178[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)              (None, 17, 17, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)              (None, 17, 17, 192)   258048      activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchNo (None, 17, 17, 192)   576         conv2d_174[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchNo (None, 17, 17, 192)   576         conv2d_179[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_174 (Activation)      (None, 17, 17, 192)   0           batch_normalization_174[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_179 (Activation)      (None, 17, 17, 192)   0           batch_normalization_179[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)              (None, 17, 17, 192)   258048      activation_174[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)              (None, 17, 17, 192)   258048      activation_179[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchNo (None, 17, 17, 192)   576         conv2d_175[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchNo (None, 17, 17, 192)   576         conv2d_180[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_175 (Activation)      (None, 17, 17, 192)   0           batch_normalization_175[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_180 (Activation)      (None, 17, 17, 192)   0           batch_normalization_180[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePoo (None, 17, 17, 768)   0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)              (None, 17, 17, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)              (None, 17, 17, 192)   258048      activation_175[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)              (None, 17, 17, 192)   258048      activation_180[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_18[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchNo (None, 17, 17, 192)   576         conv2d_173[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchNo (None, 17, 17, 192)   576         conv2d_176[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchNo (None, 17, 17, 192)   576         conv2d_181[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchNo (None, 17, 17, 192)   576         conv2d_182[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_173 (Activation)      (None, 17, 17, 192)   0           batch_normalization_173[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_176 (Activation)      (None, 17, 17, 192)   0           batch_normalization_176[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_181 (Activation)      (None, 17, 17, 192)   0           batch_normalization_181[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_182 (Activation)      (None, 17, 17, 192)   0           batch_normalization_182[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, 17, 17, 768)   0           activation_173[0][0]             \n",
      "                                                                   activation_176[0][0]             \n",
      "                                                                   activation_181[0][0]             \n",
      "                                                                   activation_182[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)              (None, 17, 17, 192)   147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchNo (None, 17, 17, 192)   576         conv2d_185[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_185 (Activation)      (None, 17, 17, 192)   0           batch_normalization_185[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)              (None, 17, 17, 192)   258048      activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchNo (None, 17, 17, 192)   576         conv2d_186[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_186 (Activation)      (None, 17, 17, 192)   0           batch_normalization_186[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)              (None, 17, 17, 192)   147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)              (None, 17, 17, 192)   258048      activation_186[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchNo (None, 17, 17, 192)   576         conv2d_183[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchNo (None, 17, 17, 192)   576         conv2d_187[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_183 (Activation)      (None, 17, 17, 192)   0           batch_normalization_183[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_187 (Activation)      (None, 17, 17, 192)   0           batch_normalization_187[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)              (None, 8, 8, 320)     552960      activation_183[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)              (None, 8, 8, 192)     331776      activation_187[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchNo (None, 8, 8, 320)     960         conv2d_184[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchNo (None, 8, 8, 192)     576         conv2d_188[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_184 (Activation)      (None, 8, 8, 320)     0           batch_normalization_184[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_188 (Activation)      (None, 8, 8, 192)     0           batch_normalization_188[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)   (None, 8, 8, 768)     0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, 8, 8, 1280)    0           activation_184[0][0]             \n",
      "                                                                   activation_188[0][0]             \n",
      "                                                                   max_pooling2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)              (None, 8, 8, 448)     573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchNo (None, 8, 8, 448)     1344        conv2d_193[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_193 (Activation)      (None, 8, 8, 448)     0           batch_normalization_193[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)              (None, 8, 8, 384)     491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)              (None, 8, 8, 384)     1548288     activation_193[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchNo (None, 8, 8, 384)     1152        conv2d_190[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchNo (None, 8, 8, 384)     1152        conv2d_194[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_190 (Activation)      (None, 8, 8, 384)     0           batch_normalization_190[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_194 (Activation)      (None, 8, 8, 384)     0           batch_normalization_194[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)              (None, 8, 8, 384)     442368      activation_190[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)              (None, 8, 8, 384)     442368      activation_190[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)              (None, 8, 8, 384)     442368      activation_194[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)              (None, 8, 8, 384)     442368      activation_194[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePoo (None, 8, 8, 1280)    0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)              (None, 8, 8, 320)     409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchNo (None, 8, 8, 384)     1152        conv2d_191[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchNo (None, 8, 8, 384)     1152        conv2d_192[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchNo (None, 8, 8, 384)     1152        conv2d_195[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchNo (None, 8, 8, 384)     1152        conv2d_196[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)              (None, 8, 8, 192)     245760      average_pooling2d_19[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchNo (None, 8, 8, 320)     960         conv2d_189[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_191 (Activation)      (None, 8, 8, 384)     0           batch_normalization_191[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_192 (Activation)      (None, 8, 8, 384)     0           batch_normalization_192[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_195 (Activation)      (None, 8, 8, 384)     0           batch_normalization_195[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_196 (Activation)      (None, 8, 8, 384)     0           batch_normalization_196[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchNo (None, 8, 8, 192)     576         conv2d_197[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_189 (Activation)      (None, 8, 8, 320)     0           batch_normalization_189[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, 8, 8, 768)     0           activation_191[0][0]             \n",
      "                                                                   activation_192[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 8, 8, 768)     0           activation_195[0][0]             \n",
      "                                                                   activation_196[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_197 (Activation)      (None, 8, 8, 192)     0           batch_normalization_197[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, 8, 8, 2048)    0           activation_189[0][0]             \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_5[0][0]              \n",
      "                                                                   activation_197[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)              (None, 8, 8, 448)     917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchNo (None, 8, 8, 448)     1344        conv2d_202[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_202 (Activation)      (None, 8, 8, 448)     0           batch_normalization_202[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)              (None, 8, 8, 384)     786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)              (None, 8, 8, 384)     1548288     activation_202[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchNo (None, 8, 8, 384)     1152        conv2d_199[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchNo (None, 8, 8, 384)     1152        conv2d_203[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_199 (Activation)      (None, 8, 8, 384)     0           batch_normalization_199[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_203 (Activation)      (None, 8, 8, 384)     0           batch_normalization_203[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)              (None, 8, 8, 384)     442368      activation_199[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)              (None, 8, 8, 384)     442368      activation_199[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)              (None, 8, 8, 384)     442368      activation_203[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)              (None, 8, 8, 384)     442368      activation_203[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePoo (None, 8, 8, 2048)    0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)              (None, 8, 8, 320)     655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchNo (None, 8, 8, 384)     1152        conv2d_200[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchNo (None, 8, 8, 384)     1152        conv2d_201[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchNo (None, 8, 8, 384)     1152        conv2d_204[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchNo (None, 8, 8, 384)     1152        conv2d_205[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)              (None, 8, 8, 192)     393216      average_pooling2d_20[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchNo (None, 8, 8, 320)     960         conv2d_198[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_200 (Activation)      (None, 8, 8, 384)     0           batch_normalization_200[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_201 (Activation)      (None, 8, 8, 384)     0           batch_normalization_201[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_204 (Activation)      (None, 8, 8, 384)     0           batch_normalization_204[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_205 (Activation)      (None, 8, 8, 384)     0           batch_normalization_205[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchNo (None, 8, 8, 192)     576         conv2d_206[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_198 (Activation)      (None, 8, 8, 320)     0           batch_normalization_198[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, 8, 8, 768)     0           activation_200[0][0]             \n",
      "                                                                   activation_201[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 8, 8, 768)     0           activation_204[0][0]             \n",
      "                                                                   activation_205[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_206 (Activation)      (None, 8, 8, 192)     0           batch_normalization_206[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, 8, 8, 2048)    0           activation_198[0][0]             \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_6[0][0]              \n",
      "                                                                   activation_206[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2D (None, 2048)          0           mixed10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 2048)          0           avg_pool[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1024)          2098176     dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 121)           124025      dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 24,024,985\n",
      "Trainable params: 23,990,553\n",
      "Non-trainable params: 34,432\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled\n",
      "Model created\n",
      "Loading training data...\n",
      "Loaded training data 3033/3033   \n",
      "Elapsed Time: Loading training\n",
      "0:00:09.734226\n",
      "Loading validation data...\n",
      "Loaded validation data516/1516   \n",
      "Elapsed Time: Loading validation\n",
      "0:00:04.542704\n",
      "Train on 3033 samples, validate on 1516 samples\n",
      "Epoch 1/100\n",
      "3033/3033 [==============================] - 51s - loss: 4.8354 - acc: 0.0099 - val_loss: 4.7856 - val_acc: 0.0106\n",
      "Epoch 2/100\n",
      "3033/3033 [==============================] - 45s - loss: 4.5532 - acc: 0.0854 - val_loss: 4.5675 - val_acc: 0.0739\n",
      "Epoch 3/100\n",
      "3033/3033 [==============================] - 45s - loss: 4.2963 - acc: 0.1306 - val_loss: 4.3392 - val_acc: 0.1214\n",
      "Epoch 4/100\n",
      "3033/3033 [==============================] - 45s - loss: 4.0868 - acc: 0.1698 - val_loss: 4.1510 - val_acc: 0.1583\n",
      "Epoch 5/100\n",
      "3033/3033 [==============================] - 45s - loss: 3.9338 - acc: 0.1932 - val_loss: 4.0421 - val_acc: 0.1570\n",
      "Epoch 6/100\n",
      "3033/3033 [==============================] - 46s - loss: 3.7905 - acc: 0.2120 - val_loss: 3.9664 - val_acc: 0.1728\n",
      "Epoch 7/100\n",
      "3033/3033 [==============================] - 46s - loss: 3.6703 - acc: 0.2298 - val_loss: 3.7555 - val_acc: 0.2104\n",
      "Epoch 8/100\n",
      "3033/3033 [==============================] - 45s - loss: 3.5328 - acc: 0.2611 - val_loss: 3.7201 - val_acc: 0.2230\n",
      "Epoch 9/100\n",
      "3033/3033 [==============================] - 46s - loss: 3.4084 - acc: 0.2829 - val_loss: 3.6214 - val_acc: 0.2414\n",
      "Epoch 10/100\n",
      "3033/3033 [==============================] - 45s - loss: 3.2674 - acc: 0.3116 - val_loss: 3.3993 - val_acc: 0.2784\n",
      "Epoch 11/100\n",
      "3033/3033 [==============================] - 46s - loss: 3.1627 - acc: 0.3409 - val_loss: 3.3945 - val_acc: 0.2883\n",
      "Epoch 12/100\n",
      "3033/3033 [==============================] - 45s - loss: 3.0299 - acc: 0.3696 - val_loss: 3.2522 - val_acc: 0.3259\n",
      "Epoch 13/100\n",
      "3033/3033 [==============================] - 45s - loss: 2.9169 - acc: 0.3983 - val_loss: 3.1628 - val_acc: 0.3463\n",
      "Epoch 14/100\n",
      "3033/3033 [==============================] - 45s - loss: 2.8079 - acc: 0.4217 - val_loss: 3.1863 - val_acc: 0.3443\n",
      "Epoch 15/100\n",
      "3033/3033 [==============================] - 45s - loss: 2.7246 - acc: 0.4342 - val_loss: 2.9459 - val_acc: 0.3865\n",
      "Epoch 16/100\n",
      "3033/3033 [==============================] - 45s - loss: 2.6322 - acc: 0.4504 - val_loss: 2.8705 - val_acc: 0.3971\n",
      "Epoch 17/100\n",
      "3033/3033 [==============================] - 45s - loss: 2.5611 - acc: 0.4702 - val_loss: 2.8018 - val_acc: 0.4149\n",
      "Epoch 18/100\n",
      "3033/3033 [==============================] - 46s - loss: 2.4721 - acc: 0.4814 - val_loss: 2.7816 - val_acc: 0.4274\n",
      "Epoch 19/100\n",
      "3033/3033 [==============================] - 45s - loss: 2.3859 - acc: 0.5077 - val_loss: 2.6895 - val_acc: 0.4360\n",
      "Epoch 20/100\n",
      "3033/3033 [==============================] - 45s - loss: 2.3435 - acc: 0.5051 - val_loss: 2.6999 - val_acc: 0.4321\n",
      "Epoch 21/100\n",
      "3033/3033 [==============================] - 45s - loss: 2.2692 - acc: 0.5219 - val_loss: 2.7270 - val_acc: 0.4347\n",
      "Epoch 22/100\n",
      "3033/3033 [==============================] - 45s - loss: 2.2230 - acc: 0.5295 - val_loss: 2.6126 - val_acc: 0.4485\n",
      "Epoch 23/100\n",
      "3033/3033 [==============================] - 45s - loss: 2.1806 - acc: 0.5325 - val_loss: 2.5991 - val_acc: 0.4591\n",
      "Epoch 24/100\n",
      "3033/3033 [==============================] - 46s - loss: 2.1114 - acc: 0.5539 - val_loss: 2.4689 - val_acc: 0.4637\n",
      "Epoch 25/100\n",
      "3033/3033 [==============================] - 45s - loss: 2.0706 - acc: 0.5572 - val_loss: 2.4561 - val_acc: 0.4690\n",
      "Epoch 26/100\n",
      "3033/3033 [==============================] - 45s - loss: 2.0051 - acc: 0.5773 - val_loss: 2.4267 - val_acc: 0.4670\n",
      "Epoch 27/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.9548 - acc: 0.5800 - val_loss: 2.3788 - val_acc: 0.4828\n",
      "Epoch 28/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.9046 - acc: 0.5922 - val_loss: 2.3674 - val_acc: 0.4782\n",
      "Epoch 29/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.8715 - acc: 0.6011 - val_loss: 2.3326 - val_acc: 0.4868\n",
      "Epoch 30/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.8331 - acc: 0.6076 - val_loss: 2.2990 - val_acc: 0.4848\n",
      "Epoch 31/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.7908 - acc: 0.6133 - val_loss: 2.3432 - val_acc: 0.4796\n",
      "Epoch 32/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.7455 - acc: 0.6261 - val_loss: 2.3888 - val_acc: 0.4723\n",
      "Epoch 33/100\n",
      "3033/3033 [==============================] - 46s - loss: 1.7081 - acc: 0.6324 - val_loss: 2.2650 - val_acc: 0.4974\n",
      "Epoch 34/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.6679 - acc: 0.6433 - val_loss: 2.2272 - val_acc: 0.5026\n",
      "Epoch 35/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.6255 - acc: 0.6492 - val_loss: 2.2018 - val_acc: 0.5040\n",
      "Epoch 36/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.5902 - acc: 0.6624 - val_loss: 2.2288 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.5495 - acc: 0.6660 - val_loss: 2.1621 - val_acc: 0.5099\n",
      "Epoch 38/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.5428 - acc: 0.6686 - val_loss: 2.1908 - val_acc: 0.5145\n",
      "Epoch 39/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.4954 - acc: 0.6766 - val_loss: 2.1293 - val_acc: 0.5158\n",
      "Epoch 40/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.4642 - acc: 0.6845 - val_loss: 2.1006 - val_acc: 0.5218\n",
      "Epoch 41/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.4345 - acc: 0.6891 - val_loss: 2.1096 - val_acc: 0.5244\n",
      "Epoch 42/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.4042 - acc: 0.6980 - val_loss: 2.1259 - val_acc: 0.5270\n",
      "Epoch 43/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.3642 - acc: 0.7056 - val_loss: 2.0604 - val_acc: 0.5310\n",
      "Epoch 44/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.3472 - acc: 0.7062 - val_loss: 2.0521 - val_acc: 0.5257\n",
      "Epoch 45/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.3182 - acc: 0.7165 - val_loss: 2.0296 - val_acc: 0.5336\n",
      "Epoch 46/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.2874 - acc: 0.7263 - val_loss: 2.0429 - val_acc: 0.5270\n",
      "Epoch 47/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.2572 - acc: 0.7366 - val_loss: 2.0036 - val_acc: 0.5363\n",
      "Epoch 48/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.2332 - acc: 0.7352 - val_loss: 2.0295 - val_acc: 0.5323\n",
      "Epoch 49/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.2140 - acc: 0.7369 - val_loss: 2.0214 - val_acc: 0.5284\n",
      "Epoch 50/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.1787 - acc: 0.7530 - val_loss: 2.0186 - val_acc: 0.5277\n",
      "Epoch 51/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.1627 - acc: 0.7570 - val_loss: 1.9768 - val_acc: 0.5317\n",
      "Epoch 52/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.1426 - acc: 0.7596 - val_loss: 1.9887 - val_acc: 0.5396\n",
      "Epoch 53/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.0955 - acc: 0.7685 - val_loss: 1.9549 - val_acc: 0.5409\n",
      "Epoch 54/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.0809 - acc: 0.7738 - val_loss: 1.9385 - val_acc: 0.5402\n",
      "Epoch 55/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.0641 - acc: 0.7801 - val_loss: 1.9235 - val_acc: 0.5442\n",
      "Epoch 56/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.0346 - acc: 0.7903 - val_loss: 1.9094 - val_acc: 0.5455\n",
      "Epoch 57/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.0112 - acc: 0.7956 - val_loss: 1.9284 - val_acc: 0.5435\n",
      "Epoch 58/100\n",
      "3033/3033 [==============================] - 45s - loss: 1.0012 - acc: 0.7976 - val_loss: 1.9387 - val_acc: 0.5409\n",
      "Epoch 59/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.9744 - acc: 0.8071 - val_loss: 1.9018 - val_acc: 0.5508\n",
      "Epoch 60/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.9469 - acc: 0.8121 - val_loss: 1.8748 - val_acc: 0.5594\n",
      "Epoch 61/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.9289 - acc: 0.8187 - val_loss: 1.9016 - val_acc: 0.5482\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3033/3033 [==============================] - 45s - loss: 0.9292 - acc: 0.8239 - val_loss: 1.8719 - val_acc: 0.5547\n",
      "Epoch 63/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.8997 - acc: 0.8269 - val_loss: 1.8592 - val_acc: 0.5607\n",
      "Epoch 64/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.8803 - acc: 0.8272 - val_loss: 1.8573 - val_acc: 0.5541\n",
      "Epoch 65/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.8676 - acc: 0.8342 - val_loss: 1.8439 - val_acc: 0.5600\n",
      "Epoch 66/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.8448 - acc: 0.8371 - val_loss: 1.8702 - val_acc: 0.5528\n",
      "Epoch 67/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.8173 - acc: 0.8447 - val_loss: 1.8951 - val_acc: 0.5501\n",
      "Epoch 68/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.8022 - acc: 0.8539 - val_loss: 1.8235 - val_acc: 0.5666\n",
      "Epoch 69/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.7882 - acc: 0.8539 - val_loss: 1.8221 - val_acc: 0.5653\n",
      "Epoch 70/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.7779 - acc: 0.8602 - val_loss: 1.8289 - val_acc: 0.5620\n",
      "Epoch 71/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.7620 - acc: 0.8586 - val_loss: 1.8511 - val_acc: 0.5640\n",
      "Epoch 72/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.7434 - acc: 0.8668 - val_loss: 1.8033 - val_acc: 0.5679\n",
      "Epoch 73/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.7203 - acc: 0.8724 - val_loss: 1.8299 - val_acc: 0.5646\n",
      "Epoch 74/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.7263 - acc: 0.8698 - val_loss: 1.7940 - val_acc: 0.5666\n",
      "Epoch 75/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.7023 - acc: 0.8747 - val_loss: 1.8078 - val_acc: 0.5574\n",
      "Epoch 76/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.6909 - acc: 0.8767 - val_loss: 1.8132 - val_acc: 0.5613\n",
      "Epoch 77/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.6700 - acc: 0.8780 - val_loss: 1.7858 - val_acc: 0.5686\n",
      "Epoch 78/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.6598 - acc: 0.8863 - val_loss: 1.7765 - val_acc: 0.5686\n",
      "Epoch 79/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.6571 - acc: 0.8787 - val_loss: 1.7760 - val_acc: 0.5759\n",
      "Epoch 80/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.6399 - acc: 0.8859 - val_loss: 1.7602 - val_acc: 0.5765\n",
      "Epoch 81/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.6158 - acc: 0.8928 - val_loss: 1.7570 - val_acc: 0.5765\n",
      "Epoch 82/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.6026 - acc: 0.8961 - val_loss: 1.7650 - val_acc: 0.5759\n",
      "Epoch 83/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.6038 - acc: 0.8981 - val_loss: 1.7843 - val_acc: 0.5739\n",
      "Epoch 84/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.5840 - acc: 0.9011 - val_loss: 1.7418 - val_acc: 0.5752\n",
      "Epoch 85/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.5745 - acc: 0.9037 - val_loss: 1.7350 - val_acc: 0.5792\n",
      "Epoch 86/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.5708 - acc: 0.9037 - val_loss: 1.7362 - val_acc: 0.5759\n",
      "Epoch 87/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.5527 - acc: 0.9077 - val_loss: 1.7422 - val_acc: 0.5818\n",
      "Epoch 88/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.5432 - acc: 0.9070 - val_loss: 1.7334 - val_acc: 0.5811\n",
      "Epoch 89/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.5277 - acc: 0.9143 - val_loss: 1.7694 - val_acc: 0.5739\n",
      "Epoch 90/100\n",
      "3033/3033 [==============================] - 46s - loss: 0.5221 - acc: 0.9143 - val_loss: 1.7216 - val_acc: 0.5858\n",
      "Epoch 91/100\n",
      "3033/3033 [==============================] - 46s - loss: 0.5108 - acc: 0.9143 - val_loss: 1.7321 - val_acc: 0.5785\n",
      "Epoch 92/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.5068 - acc: 0.9199 - val_loss: 1.7252 - val_acc: 0.5811\n",
      "Epoch 93/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.4907 - acc: 0.9172 - val_loss: 1.7600 - val_acc: 0.5785\n",
      "Epoch 94/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.4889 - acc: 0.9186 - val_loss: 1.7160 - val_acc: 0.5785\n",
      "Epoch 95/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.4724 - acc: 0.9261 - val_loss: 1.7147 - val_acc: 0.5805\n",
      "Epoch 96/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.4626 - acc: 0.9242 - val_loss: 1.6987 - val_acc: 0.5904\n",
      "Epoch 97/100\n",
      "3033/3033 [==============================] - 46s - loss: 0.4571 - acc: 0.9232 - val_loss: 1.7471 - val_acc: 0.5719\n",
      "Epoch 98/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.4499 - acc: 0.9291 - val_loss: 1.6917 - val_acc: 0.5798\n",
      "Epoch 99/100\n",
      "3033/3033 [==============================] - 45s - loss: 0.4387 - acc: 0.9314 - val_loss: 1.7036 - val_acc: 0.5897\n",
      "Epoch 100/100\n",
      "3033/3033 [==============================] - 46s - loss: 0.4427 - acc: 0.9271 - val_loss: 1.6866 - val_acc: 0.5818\n",
      "Elapsed Time: Training\n",
      "1:16:26.817994\n",
      "{'acc': [0.0098911966309270724, 0.085393998650308889, 0.13056379811641133, 0.16979887885030173, 0.19320804550089224, 0.21200131964671742, 0.22980547363986836, 0.26112759532882873, 0.28288823036993449, 0.31157270191802938, 0.34091658506541217, 0.36960105585690345, 0.39828552824021013, 0.42169469221566636, 0.43422354205072106, 0.45037916056047839, 0.47016155422028638, 0.48137157839043399, 0.50774810530743975, 0.50511045454753489, 0.52192548654317616, 0.52950873576961965, 0.53247609558649434, 0.55390702538312642, 0.55720408653371845, 0.57731619328899109, 0.57995384294838159, 0.59215298913077796, 0.6010550630493523, 0.60764919353561198, 0.61325420595968361, 0.62611276430145102, 0.63237719265808578, 0.64325750732909248, 0.64919222499763773, 0.66238048976300146, 0.66600725472346811, 0.66864490896178441, 0.67655786837519016, 0.68447082647190916, 0.68908671459426907, 0.6979887947327148, 0.70557204133561058, 0.7062314557942706, 0.71645235665513474, 0.72634355321482313, 0.73656445898869782, 0.7352456284402582, 0.73689416883174952, 0.75304978443300452, 0.75700626625230205, 0.75964391101833384, 0.76854599210007768, 0.77382130089114298, 0.78008571993270959, 0.79030662336799129, 0.79558193086202178, 0.79756016704535426, 0.80712166095463855, 0.81206725860561746, 0.81866138548572742, 0.82393668936378206, 0.8269040531110653, 0.82723375806075838, 0.83415759187541771, 0.83712495397192943, 0.84470820617565734, 0.85393998959337258, 0.85393998794260095, 0.86020441578828266, 0.85855588030980201, 0.86679854335621409, 0.87240355642880307, 0.86976590614054727, 0.87471150605151093, 0.87668974549708256, 0.87800856655358561, 0.88625123156520191, 0.87866798101224564, 0.8859215279321957, 0.89284536599169617, 0.89614242845897507, 0.89812066922123346, 0.90108802903810825, 0.90372567869749865, 0.90372568064305081, 0.90768216348425457, 0.90702274442701658, 0.91427628906732972, 0.91427628938176242, 0.91427628971584707, 0.9198813077014466, 0.91724364986680662, 0.91856247780152445, 0.9261457260748438, 0.92416748531258541, 0.92317836820352128, 0.92911308227574274, 0.9314210309158486, 0.92713484611206232], 'loss': [4.8353618122821507, 4.5532360734068593, 4.2962835761842815, 4.0868087143462519, 3.9338239092973053, 3.7905151932851888, 3.6703214157229009, 3.5327834845611141, 3.4083559250540754, 3.267394419279265, 3.1627114892123833, 3.0299302754211928, 2.9169447911756485, 2.8078546265426971, 2.7246399748808789, 2.6321855200582944, 2.5610683197005133, 2.4720842831998699, 2.3858895207489046, 2.3435155735368034, 2.2692320117296418, 2.2229930730373835, 2.1805707243775676, 2.1114000111494056, 2.0705559924220314, 2.0051449089996733, 1.9547602913382027, 1.9045704297016368, 1.8715016271193115, 1.8331273442009592, 1.7908196501554219, 1.7455181684424843, 1.7080570730957072, 1.6679389240951614, 1.6254851429367316, 1.5902303319302793, 1.5495466930104529, 1.5427993940041476, 1.4954493373602953, 1.4641981607139052, 1.4344520599504842, 1.4041720019525088, 1.3641840826352751, 1.347207479181362, 1.3181599119178855, 1.2874043785303368, 1.2571520641067813, 1.2331983525093499, 1.214020720123262, 1.1786697827822454, 1.1626805203840593, 1.142590921663271, 1.0955440896279813, 1.0809116431521457, 1.0641491169824169, 1.0345856316640674, 1.0111536237614169, 1.0012357705817772, 0.97437648658425435, 0.94685140101775223, 0.92886725177161178, 0.92916389432159385, 0.8996647539761371, 0.88030139854785205, 0.86755450464419082, 0.84483477690414044, 0.81732743426277976, 0.80215728618978388, 0.78824176365418119, 0.77785735605103401, 0.76203032401462534, 0.74344247084343118, 0.72032264212040154, 0.72634226881628416, 0.70228723191680431, 0.69085022006300545, 0.67001276768122497, 0.65976232533953272, 0.65709603758405388, 0.63990058928010807, 0.61577107369447748, 0.60262913869781698, 0.60375497115550558, 0.58403266209247995, 0.57447955229476544, 0.57084265446607874, 0.55265246817588487, 0.54318256309195156, 0.52771342777396213, 0.5220976804216978, 0.51082051322085209, 0.50678059800678144, 0.49069893798378489, 0.48891132842028373, 0.47238274230604865, 0.46263543144728225, 0.45714776397262358, 0.44990148167090571, 0.43871426415294063, 0.44266652685559077], 'val_acc': [0.010554089473860245, 0.07387862719182603, 0.12137203179004953, 0.15831134654581547, 0.15699208451626639, 0.17282321848132523, 0.21042216272341543, 0.22295514606234265, 0.2414248026415981, 0.27836411642918174, 0.28825857739964389, 0.3258575195530159, 0.34630607027255766, 0.34432717613227137, 0.38654353605254027, 0.39709762306908503, 0.41490765556811027, 0.4274406339924065, 0.43601583023027252, 0.43205804580277063, 0.434696568033626, 0.44854880999134839, 0.45910290044813484, 0.46372031225849897, 0.46899736155620664, 0.46701846509621453, 0.48284959930700488, 0.47823218847956694, 0.48680738837391846, 0.48482849745763007, 0.4795514480812883, 0.47229550983314461, 0.49736147651099905, 0.50263851633329815, 0.50395778450613604, 0.50000000196585237, 0.50989445851314663, 0.51451187327228942, 0.51583113161586525, 0.52176780927936128, 0.52440632981958368, 0.52704485366243803, 0.53100263879764675, 0.52572559960442045, 0.53364116228664771, 0.52704485661121658, 0.53627968121487102, 0.53232190036522054, 0.52836411066923417, 0.52770448757193023, 0.53166227074128658, 0.53957783468165943, 0.54089710187157103, 0.54023746733300604, 0.5441952507775818, 0.54551451002544971, 0.54353562142886713, 0.54089709856893897, 0.55079155574530603, 0.5593667585884361, 0.54815303457601094, 0.5547493444583661, 0.56068602212186225, 0.55408970465131679, 0.56002638821237005, 0.55277044567866818, 0.55013192969922342, 0.56662268771502466, 0.56530343365700708, 0.5620052781457322, 0.56398416941587404, 0.56794195286044968, 0.56464380493736521, 0.56662269093902251, 0.55738786535244189, 0.56134565048765062, 0.56860158480408951, 0.5686015857870157, 0.57585752144023428, 0.57651715338387399, 0.57651715534972636, 0.57585752242316046, 0.5738786324897982, 0.57519788654781578, 0.57915567427794978, 0.57585752537193902, 0.58179419650880515, 0.58113456912594297, 0.57387862855809346, 0.58575198290215946, 0.57849604331723614, 0.58113457109179534, 0.57849604162660306, 0.57849604528308862, 0.58047493423352459, 0.59036939801515564, 0.57189973665887883, 0.57981530692929639, 0.58970976276888387, 0.58179419812080413], 'val_loss': [4.7856314301805316, 4.5674507485845162, 4.3392356819716484, 4.1509510357335877, 4.0421168193968118, 3.966356315839259, 3.7554888866822136, 3.7200875908215001, 3.6214188922363726, 3.3993244819087529, 3.3945124929372743, 3.2522484752936855, 3.1628454656273832, 3.186254733470625, 2.9459468582374755, 2.8704524008768528, 2.8017985509379244, 2.7815879935639516, 2.6894544293823848, 2.6998918471676063, 2.7270065401349028, 2.6125900245278997, 2.599105982163965, 2.4688904073118847, 2.4561318520820237, 2.4267275338122585, 2.3787700673835572, 2.367359167824949, 2.3326016820200515, 2.2989916864359912, 2.3432148669829154, 2.3888146628805074, 2.264962965548825, 2.2272417391195773, 2.201819351291908, 2.2288303332781729, 2.1620585764303684, 2.1907731824625767, 2.1292828678455704, 2.1006216796847319, 2.1096220277544693, 2.1258843563162872, 2.0603821600018204, 2.0521465041392082, 2.029569841940988, 2.0429438626231491, 2.0035962228095627, 2.0295105667730748, 2.0213918376094746, 2.0186229090262842, 1.9768075118907837, 1.9886644517211611, 1.9548674068538998, 1.9385251695373757, 1.9234639102676614, 1.9094431029146139, 1.9283994474008403, 1.9387045718120082, 1.9018491877729471, 1.8747685249688444, 1.9016127743632938, 1.8719149241346797, 1.8592462168519919, 1.8572814267983853, 1.8438676581533728, 1.8702248039220442, 1.8950766606507012, 1.8234931466447333, 1.8220603758552774, 1.8288880866561528, 1.8511248716892856, 1.8033059571223398, 1.8298765793639311, 1.7939533386821798, 1.8078018559000424, 1.8132331305254732, 1.7857531861139162, 1.7764531576853628, 1.7760014595331177, 1.7602255666790663, 1.7570115658098286, 1.7649929196350178, 1.784262447998832, 1.7418290634583042, 1.7349539812762378, 1.7361883598141432, 1.7421964539072445, 1.7333618301829437, 1.7693859834155181, 1.7216094692967499, 1.7321433239373178, 1.7252423926834066, 1.7599862110960767, 1.7160273189595003, 1.7147174450841616, 1.6987136497032045, 1.7471249065801777, 1.6916724857051013, 1.7036103787082482, 1.6865963575707892]}\n",
      "Model weights saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing data...\n",
      "Loaded testing data  25785/25785   \n",
      "Elapsed Time: Loading testing\n",
      "0:01:32.297359\n",
      "25785/25785 [==============================] - 123s   \n",
      "Elapsed Time: Testing\n",
      "0:02:03.180269\n",
      "[1.5970235549828007, 0.6132247469349843]\n",
      "['loss', 'acc']\n"
     ]
    }
   ],
   "source": [
    "description = \"\"\"Inception V3 - +0 inception + 1024 dense (extended) output\"\"\"\n",
    "logger(\"-----------------------------------------------------------------\")\n",
    "logger(ID)\n",
    "logger(description)\n",
    "\n",
    "# Make model\n",
    "model = load_model()\n",
    "print(\"Model created\")\n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Load the training data\n",
    "X_train, Y_train = cal.load_training()\n",
    "\n",
    "# Print time loading training\n",
    "elapsed_time = datetime.now() - start_time\n",
    "logger(\"Elapsed Time: Loading training\")\n",
    "logger(elapsed_time)   \n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Load the validation data\n",
    "X_val, Y_val = cal.load_validation()\n",
    "\n",
    "# Print time loading validation\n",
    "elapsed_time = datetime.now() - start_time\n",
    "logger(\"Elapsed Time: Loading validation\")\n",
    "logger(elapsed_time)  \n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Train model and store stats in history\n",
    "history = model.fit(x=X_train,y=Y_train,batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,validation_data=(X_val,Y_val))\n",
    "\n",
    "history = history.history\n",
    "\n",
    "# Print total time\n",
    "elapsed_time = datetime.now() - start_time\n",
    "logger(\"Elapsed Time: Training\")\n",
    "logger(elapsed_time)   \n",
    "\n",
    "# Save model weights\n",
    "model_dir = 'models'\n",
    "\n",
    "model_name = '{}'.format(ID)\n",
    "model_name += '.h5'\n",
    "model_path = os.path.join(model_dir,model_name)\n",
    "\n",
    "model.save(model_path)\n",
    "\n",
    "logger(history)\n",
    "print(\"Model weights saved\")\n",
    "\n",
    "accuracy = {'Training': history['acc'],\n",
    "            'Validation': history['val_acc']}\n",
    "\n",
    "loss = {'Training': history['loss'],\n",
    "        'Validation': history['val_loss']}\n",
    "\n",
    "# Plot training vs validation accuracy  \n",
    "plot(accuracy, \"Accuracy: Training vs Validation\",\n",
    "        'Epochs', 'Accuracy', '{}_accuracy_train_val'.format(ID))\n",
    "\n",
    "# Plot training vs validation loss  \n",
    "plot(loss, \"Loss: Training vs Validation\",\n",
    "        'Epochs', 'Loss', '{}_loss_train_val'.format(ID))\n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Loading testing data\n",
    "X_test, Y_test = cal.load_testing()\n",
    "\n",
    "# Print time loading testing\n",
    "elapsed_time = datetime.now() - start_time\n",
    "logger(\"Elapsed Time: Loading testing\")\n",
    "logger(elapsed_time)  \n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Test model\n",
    "metrics = model.evaluate(x=X_test,y=Y_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Print time testing\n",
    "elapsed_time = datetime.now() - start_time\n",
    "logger(\"Elapsed Time: Testing\")\n",
    "logger(elapsed_time)  \n",
    "\n",
    "logger(metrics)\n",
    "logger(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
