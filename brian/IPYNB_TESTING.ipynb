{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import native modules\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime                    # Use to record time\n",
    "\n",
    "# Import Keras functions\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation, concatenate,\\\n",
    "                GlobalAveragePooling2D, Conv2D, Concatenate, AveragePooling2D, BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as backK\n",
    "\n",
    "# Import matrix and plotting\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')                           # Stops from plotting to screen\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import OpenCV\n",
    "import cv2\n",
    "\n",
    "# Import custom dataset class\n",
    "from dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from plankton_resized\n",
      "Split 30336 data into 3033 training, 1516 validation, and 25785 testing data.\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = 'plankton_resized'\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 50\n",
    "NUM_TRAIN,NUM_VAL,NUM_TEST = 10,5,85\n",
    "\n",
    "IMAGE_WIDTH,IMAGE_HEIGHT,NUM_CHANNELS = 299,299,3\n",
    "\n",
    "\n",
    "ID = \"{}_{}_{}_{}_{}_{}_{}\".format(\"INCEPTION-AVG-2048relu_EX\",DATASET_NAME,\n",
    "                                EPOCHS,BATCH_SIZE,NUM_TRAIN,NUM_VAL,NUM_TEST)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "cal = Dataset(DATASET_NAME,IMAGE_HEIGHT,IMAGE_WIDTH,resized=True)\n",
    "cal.read_data()\n",
    "cal.train_val_test_split(NUM_TRAIN,NUM_VAL,NUM_TEST)\n",
    "num_classes = cal.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logger(message):\n",
    "    \"\"\"Logs any message into a file\"\"\"\n",
    "    with open('./models/stats.txt', 'a+') as f:\n",
    "        print >>f, message\n",
    "        print(message)\n",
    "\n",
    "def plot(datas, title, xlabel, ylabel, file_name):\n",
    "    \"\"\"Plots the data\"\"\"\n",
    "    plt.figure()\n",
    "    for key,value in datas.iteritems():\n",
    "        plt.plot(value, label=key)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    plots_dir = 'plots'\n",
    "    file_name + '.png'\n",
    "    plot_path = os.path.join(plots_dir,file_name)    \n",
    "    plt.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from inception_v3.py in the keras repository\n",
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), name=None):\n",
    "    \"\"\"Utility function to apply conv + BN (Batch Normalization).\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: filters in `Conv2D`.\n",
    "        num_row: height of the convolution kernel.\n",
    "        num_col: width of the convolution kernel.\n",
    "        padding: padding mode in `Conv2D`.\n",
    "        strides: strides in `Conv2D`.\n",
    "        name: name of the ops; will become `name + '_conv'`\n",
    "            for the convolution and `name + '_bn'` for the\n",
    "            batch norm layer.\n",
    "    # Returns\n",
    "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
    "    \"\"\"\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    if backK.image_data_format() == 'channels_first':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False, name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    x = Activation('relu', name=name)(x)\n",
    "    return x\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Returns a pretrained model\"\"\"\n",
    "    \n",
    "    # Loads base model\n",
    "    base_model = InceptionV3(include_top=False, weights='imagenet',input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
    "    print(\"Model weights loaded.\")\n",
    "    \n",
    "    # Typical Output\n",
    "    x = base_model.output\n",
    "    \n",
    "    # For evaluating pre-inception layers\n",
    "    #x = base_model.layers[-32].output  # \"-1\"st layer\n",
    "    #x = base_model.layers[-63].output  # \"-2\"nd layer\n",
    "\n",
    "    # Inception modules\n",
    "    inception_count = 0          # number of inception layers to add\n",
    "    for i in range(inception_count):\n",
    "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
    "\n",
    "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
    "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
    "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
    "        branch3x3 = concatenate([branch3x3_1, branch3x3_2], axis=3, name='mixed11_'+str(i)+'_added')\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
    "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
    "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
    "        branch3x3dbl = concatenate([branch3x3dbl_1, branch3x3dbl_2], axis=3)\n",
    "\n",
    "        branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = concatenate([branch1x1, branch3x3, branch3x3dbl, branch_pool], axis=3, name='mixed'+str(12+i)+'_added')\n",
    "        \n",
    "    # Add layers (the typical ones)\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(2048,activation='relu')(x)\n",
    "\n",
    "    # Final fully connected layer to work with our data\n",
    "    predictions = Dense(num_classes,activation='softmax')(x)\n",
    "\n",
    "    # Build a final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    print(\"Model structure\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizers.SGD(lr=1e-4,momentum=0.9),\n",
    "                'categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(\"Model compiled\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "INCEPTION-AVG-2048relu_EX_plankton_resized_100_50_10_5_85\n",
      "Inception V3 - +0 inception + 2048 dense (extended) output\n",
      "Model weights loaded.\n",
      "Model structure\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 299, 299, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)               (None, 149, 149, 32)  864         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNor (None, 149, 149, 32)  96          conv2d_95[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, 149, 149, 32)  0           batch_normalization_95[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)               (None, 147, 147, 32)  9216        activation_95[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNor (None, 147, 147, 32)  96          conv2d_96[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, 147, 147, 32)  0           batch_normalization_96[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)               (None, 147, 147, 64)  18432       activation_96[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNor (None, 147, 147, 64)  192         conv2d_97[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, 147, 147, 64)  0           batch_normalization_97[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 73, 73, 64)    0           activation_97[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)               (None, 73, 73, 80)    5120        max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNor (None, 73, 73, 80)    240         conv2d_98[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, 73, 73, 80)    0           batch_normalization_98[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)               (None, 71, 71, 192)   138240      activation_98[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNor (None, 71, 71, 192)   576         conv2d_99[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, 71, 71, 192)   0           batch_normalization_99[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, 35, 35, 192)   0           activation_99[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)              (None, 35, 35, 64)    12288       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchNo (None, 35, 35, 64)    192         conv2d_103[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_103 (Activation)      (None, 35, 35, 64)    0           batch_normalization_103[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)              (None, 35, 35, 48)    9216        max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)              (None, 35, 35, 96)    55296       activation_103[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchNo (None, 35, 35, 48)    144         conv2d_101[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchNo (None, 35, 35, 96)    288         conv2d_104[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, 35, 35, 48)    0           batch_normalization_101[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_104 (Activation)      (None, 35, 35, 96)    0           batch_normalization_104[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePoo (None, 35, 35, 192)   0           max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)              (None, 35, 35, 64)    12288       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)              (None, 35, 35, 64)    76800       activation_101[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)              (None, 35, 35, 96)    82944       activation_104[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)              (None, 35, 35, 32)    6144        average_pooling2d_10[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchNo (None, 35, 35, 64)    192         conv2d_100[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchNo (None, 35, 35, 64)    192         conv2d_102[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchNo (None, 35, 35, 96)    288         conv2d_105[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchNo (None, 35, 35, 32)    96          conv2d_106[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, 35, 35, 64)    0           batch_normalization_100[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, 35, 35, 64)    0           batch_normalization_102[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_105 (Activation)      (None, 35, 35, 96)    0           batch_normalization_105[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_106 (Activation)      (None, 35, 35, 32)    0           batch_normalization_106[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, 35, 35, 256)   0           activation_100[0][0]             \n",
      "                                                                   activation_102[0][0]             \n",
      "                                                                   activation_105[0][0]             \n",
      "                                                                   activation_106[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)              (None, 35, 35, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchNo (None, 35, 35, 64)    192         conv2d_110[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_110 (Activation)      (None, 35, 35, 64)    0           batch_normalization_110[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)              (None, 35, 35, 48)    12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)              (None, 35, 35, 96)    55296       activation_110[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchNo (None, 35, 35, 48)    144         conv2d_108[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchNo (None, 35, 35, 96)    288         conv2d_111[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_108 (Activation)      (None, 35, 35, 48)    0           batch_normalization_108[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_111 (Activation)      (None, 35, 35, 96)    0           batch_normalization_111[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePoo (None, 35, 35, 256)   0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)              (None, 35, 35, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)              (None, 35, 35, 64)    76800       activation_108[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)              (None, 35, 35, 96)    82944       activation_111[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)              (None, 35, 35, 64)    16384       average_pooling2d_11[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchNo (None, 35, 35, 64)    192         conv2d_107[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchNo (None, 35, 35, 64)    192         conv2d_109[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchNo (None, 35, 35, 96)    288         conv2d_112[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchNo (None, 35, 35, 64)    192         conv2d_113[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_107 (Activation)      (None, 35, 35, 64)    0           batch_normalization_107[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_109 (Activation)      (None, 35, 35, 64)    0           batch_normalization_109[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_112 (Activation)      (None, 35, 35, 96)    0           batch_normalization_112[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_113 (Activation)      (None, 35, 35, 64)    0           batch_normalization_113[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, 35, 35, 288)   0           activation_107[0][0]             \n",
      "                                                                   activation_109[0][0]             \n",
      "                                                                   activation_112[0][0]             \n",
      "                                                                   activation_113[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)              (None, 35, 35, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchNo (None, 35, 35, 64)    192         conv2d_117[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_117 (Activation)      (None, 35, 35, 64)    0           batch_normalization_117[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)              (None, 35, 35, 48)    13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)              (None, 35, 35, 96)    55296       activation_117[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchNo (None, 35, 35, 48)    144         conv2d_115[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchNo (None, 35, 35, 96)    288         conv2d_118[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_115 (Activation)      (None, 35, 35, 48)    0           batch_normalization_115[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_118 (Activation)      (None, 35, 35, 96)    0           batch_normalization_118[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePoo (None, 35, 35, 288)   0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)              (None, 35, 35, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)              (None, 35, 35, 64)    76800       activation_115[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)              (None, 35, 35, 96)    82944       activation_118[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)              (None, 35, 35, 64)    18432       average_pooling2d_12[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchNo (None, 35, 35, 64)    192         conv2d_114[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchNo (None, 35, 35, 64)    192         conv2d_116[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchNo (None, 35, 35, 96)    288         conv2d_119[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchNo (None, 35, 35, 64)    192         conv2d_120[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_114 (Activation)      (None, 35, 35, 64)    0           batch_normalization_114[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_116 (Activation)      (None, 35, 35, 64)    0           batch_normalization_116[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_119 (Activation)      (None, 35, 35, 96)    0           batch_normalization_119[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_120 (Activation)      (None, 35, 35, 64)    0           batch_normalization_120[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, 35, 35, 288)   0           activation_114[0][0]             \n",
      "                                                                   activation_116[0][0]             \n",
      "                                                                   activation_119[0][0]             \n",
      "                                                                   activation_120[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)              (None, 35, 35, 64)    18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchNo (None, 35, 35, 64)    192         conv2d_122[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_122 (Activation)      (None, 35, 35, 64)    0           batch_normalization_122[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)              (None, 35, 35, 96)    55296       activation_122[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchNo (None, 35, 35, 96)    288         conv2d_123[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_123 (Activation)      (None, 35, 35, 96)    0           batch_normalization_123[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)              (None, 17, 17, 384)   995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)              (None, 17, 17, 96)    82944       activation_123[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchNo (None, 17, 17, 384)   1152        conv2d_121[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchNo (None, 17, 17, 96)    288         conv2d_124[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_121 (Activation)      (None, 17, 17, 384)   0           batch_normalization_121[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_124 (Activation)      (None, 17, 17, 96)    0           batch_normalization_124[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)   (None, 17, 17, 288)   0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, 17, 17, 768)   0           activation_121[0][0]             \n",
      "                                                                   activation_124[0][0]             \n",
      "                                                                   max_pooling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)              (None, 17, 17, 128)   98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchNo (None, 17, 17, 128)   384         conv2d_129[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, 17, 17, 128)   0           batch_normalization_129[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)              (None, 17, 17, 128)   114688      activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchNo (None, 17, 17, 128)   384         conv2d_130[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, 17, 17, 128)   0           batch_normalization_130[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)              (None, 17, 17, 128)   98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)              (None, 17, 17, 128)   114688      activation_130[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchNo (None, 17, 17, 128)   384         conv2d_126[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchNo (None, 17, 17, 128)   384         conv2d_131[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_126 (Activation)      (None, 17, 17, 128)   0           batch_normalization_126[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, 17, 17, 128)   0           batch_normalization_131[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)              (None, 17, 17, 128)   114688      activation_126[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)              (None, 17, 17, 128)   114688      activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchNo (None, 17, 17, 128)   384         conv2d_127[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchNo (None, 17, 17, 128)   384         conv2d_132[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, 17, 17, 128)   0           batch_normalization_127[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, 17, 17, 128)   0           batch_normalization_132[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePoo (None, 17, 17, 768)   0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)              (None, 17, 17, 192)   147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)              (None, 17, 17, 192)   172032      activation_127[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)              (None, 17, 17, 192)   172032      activation_132[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_13[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchNo (None, 17, 17, 192)   576         conv2d_125[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchNo (None, 17, 17, 192)   576         conv2d_128[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchNo (None, 17, 17, 192)   576         conv2d_133[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchNo (None, 17, 17, 192)   576         conv2d_134[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_125 (Activation)      (None, 17, 17, 192)   0           batch_normalization_125[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, 17, 17, 192)   0           batch_normalization_128[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, 17, 17, 192)   0           batch_normalization_133[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, 17, 17, 192)   0           batch_normalization_134[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, 17, 17, 768)   0           activation_125[0][0]             \n",
      "                                                                   activation_128[0][0]             \n",
      "                                                                   activation_133[0][0]             \n",
      "                                                                   activation_134[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)              (None, 17, 17, 160)   122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchNo (None, 17, 17, 160)   480         conv2d_139[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, 17, 17, 160)   0           batch_normalization_139[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)              (None, 17, 17, 160)   179200      activation_139[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchNo (None, 17, 17, 160)   480         conv2d_140[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, 17, 17, 160)   0           batch_normalization_140[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)              (None, 17, 17, 160)   122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)              (None, 17, 17, 160)   179200      activation_140[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchNo (None, 17, 17, 160)   480         conv2d_136[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchNo (None, 17, 17, 160)   480         conv2d_141[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, 17, 17, 160)   0           batch_normalization_136[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_141 (Activation)      (None, 17, 17, 160)   0           batch_normalization_141[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)              (None, 17, 17, 160)   179200      activation_136[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)              (None, 17, 17, 160)   179200      activation_141[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchNo (None, 17, 17, 160)   480         conv2d_137[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchNo (None, 17, 17, 160)   480         conv2d_142[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, 17, 17, 160)   0           batch_normalization_137[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_142 (Activation)      (None, 17, 17, 160)   0           batch_normalization_142[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePoo (None, 17, 17, 768)   0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)              (None, 17, 17, 192)   147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)              (None, 17, 17, 192)   215040      activation_137[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)              (None, 17, 17, 192)   215040      activation_142[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_14[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchNo (None, 17, 17, 192)   576         conv2d_135[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchNo (None, 17, 17, 192)   576         conv2d_138[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchNo (None, 17, 17, 192)   576         conv2d_143[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchNo (None, 17, 17, 192)   576         conv2d_144[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, 17, 17, 192)   0           batch_normalization_135[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, 17, 17, 192)   0           batch_normalization_138[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, 17, 17, 192)   0           batch_normalization_143[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_144 (Activation)      (None, 17, 17, 192)   0           batch_normalization_144[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, 17, 17, 768)   0           activation_135[0][0]             \n",
      "                                                                   activation_138[0][0]             \n",
      "                                                                   activation_143[0][0]             \n",
      "                                                                   activation_144[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)              (None, 17, 17, 160)   122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchNo (None, 17, 17, 160)   480         conv2d_149[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_149 (Activation)      (None, 17, 17, 160)   0           batch_normalization_149[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)              (None, 17, 17, 160)   179200      activation_149[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchNo (None, 17, 17, 160)   480         conv2d_150[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_150 (Activation)      (None, 17, 17, 160)   0           batch_normalization_150[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)              (None, 17, 17, 160)   122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)              (None, 17, 17, 160)   179200      activation_150[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchNo (None, 17, 17, 160)   480         conv2d_146[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchNo (None, 17, 17, 160)   480         conv2d_151[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_146 (Activation)      (None, 17, 17, 160)   0           batch_normalization_146[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_151 (Activation)      (None, 17, 17, 160)   0           batch_normalization_151[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)              (None, 17, 17, 160)   179200      activation_146[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)              (None, 17, 17, 160)   179200      activation_151[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchNo (None, 17, 17, 160)   480         conv2d_147[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchNo (None, 17, 17, 160)   480         conv2d_152[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_147 (Activation)      (None, 17, 17, 160)   0           batch_normalization_147[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_152 (Activation)      (None, 17, 17, 160)   0           batch_normalization_152[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePoo (None, 17, 17, 768)   0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)              (None, 17, 17, 192)   147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)              (None, 17, 17, 192)   215040      activation_147[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)              (None, 17, 17, 192)   215040      activation_152[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_15[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchNo (None, 17, 17, 192)   576         conv2d_145[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchNo (None, 17, 17, 192)   576         conv2d_148[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchNo (None, 17, 17, 192)   576         conv2d_153[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchNo (None, 17, 17, 192)   576         conv2d_154[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_145 (Activation)      (None, 17, 17, 192)   0           batch_normalization_145[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_148 (Activation)      (None, 17, 17, 192)   0           batch_normalization_148[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_153 (Activation)      (None, 17, 17, 192)   0           batch_normalization_153[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_154 (Activation)      (None, 17, 17, 192)   0           batch_normalization_154[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, 17, 17, 768)   0           activation_145[0][0]             \n",
      "                                                                   activation_148[0][0]             \n",
      "                                                                   activation_153[0][0]             \n",
      "                                                                   activation_154[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)              (None, 17, 17, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchNo (None, 17, 17, 192)   576         conv2d_159[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_159 (Activation)      (None, 17, 17, 192)   0           batch_normalization_159[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)              (None, 17, 17, 192)   258048      activation_159[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchNo (None, 17, 17, 192)   576         conv2d_160[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_160 (Activation)      (None, 17, 17, 192)   0           batch_normalization_160[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)              (None, 17, 17, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)              (None, 17, 17, 192)   258048      activation_160[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchNo (None, 17, 17, 192)   576         conv2d_156[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchNo (None, 17, 17, 192)   576         conv2d_161[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_156 (Activation)      (None, 17, 17, 192)   0           batch_normalization_156[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_161 (Activation)      (None, 17, 17, 192)   0           batch_normalization_161[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)              (None, 17, 17, 192)   258048      activation_156[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)              (None, 17, 17, 192)   258048      activation_161[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchNo (None, 17, 17, 192)   576         conv2d_157[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchNo (None, 17, 17, 192)   576         conv2d_162[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_157 (Activation)      (None, 17, 17, 192)   0           batch_normalization_157[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_162 (Activation)      (None, 17, 17, 192)   0           batch_normalization_162[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePoo (None, 17, 17, 768)   0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)              (None, 17, 17, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)              (None, 17, 17, 192)   258048      activation_157[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)              (None, 17, 17, 192)   258048      activation_162[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_16[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchNo (None, 17, 17, 192)   576         conv2d_155[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchNo (None, 17, 17, 192)   576         conv2d_158[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchNo (None, 17, 17, 192)   576         conv2d_163[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchNo (None, 17, 17, 192)   576         conv2d_164[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_155 (Activation)      (None, 17, 17, 192)   0           batch_normalization_155[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_158 (Activation)      (None, 17, 17, 192)   0           batch_normalization_158[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_163 (Activation)      (None, 17, 17, 192)   0           batch_normalization_163[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_164 (Activation)      (None, 17, 17, 192)   0           batch_normalization_164[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, 17, 17, 768)   0           activation_155[0][0]             \n",
      "                                                                   activation_158[0][0]             \n",
      "                                                                   activation_163[0][0]             \n",
      "                                                                   activation_164[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)              (None, 17, 17, 192)   147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchNo (None, 17, 17, 192)   576         conv2d_167[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_167 (Activation)      (None, 17, 17, 192)   0           batch_normalization_167[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)              (None, 17, 17, 192)   258048      activation_167[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchNo (None, 17, 17, 192)   576         conv2d_168[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_168 (Activation)      (None, 17, 17, 192)   0           batch_normalization_168[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)              (None, 17, 17, 192)   147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)              (None, 17, 17, 192)   258048      activation_168[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchNo (None, 17, 17, 192)   576         conv2d_165[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchNo (None, 17, 17, 192)   576         conv2d_169[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_165 (Activation)      (None, 17, 17, 192)   0           batch_normalization_165[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_169 (Activation)      (None, 17, 17, 192)   0           batch_normalization_169[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)              (None, 8, 8, 320)     552960      activation_165[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)              (None, 8, 8, 192)     331776      activation_169[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchNo (None, 8, 8, 320)     960         conv2d_166[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchNo (None, 8, 8, 192)     576         conv2d_170[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_166 (Activation)      (None, 8, 8, 320)     0           batch_normalization_166[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_170 (Activation)      (None, 8, 8, 192)     0           batch_normalization_170[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)   (None, 8, 8, 768)     0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, 8, 8, 1280)    0           activation_166[0][0]             \n",
      "                                                                   activation_170[0][0]             \n",
      "                                                                   max_pooling2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)              (None, 8, 8, 448)     573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchNo (None, 8, 8, 448)     1344        conv2d_175[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_175 (Activation)      (None, 8, 8, 448)     0           batch_normalization_175[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)              (None, 8, 8, 384)     491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)              (None, 8, 8, 384)     1548288     activation_175[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchNo (None, 8, 8, 384)     1152        conv2d_172[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchNo (None, 8, 8, 384)     1152        conv2d_176[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_172 (Activation)      (None, 8, 8, 384)     0           batch_normalization_172[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_176 (Activation)      (None, 8, 8, 384)     0           batch_normalization_176[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)              (None, 8, 8, 384)     442368      activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)              (None, 8, 8, 384)     442368      activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)              (None, 8, 8, 384)     442368      activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)              (None, 8, 8, 384)     442368      activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePoo (None, 8, 8, 1280)    0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)              (None, 8, 8, 320)     409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchNo (None, 8, 8, 384)     1152        conv2d_173[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchNo (None, 8, 8, 384)     1152        conv2d_174[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchNo (None, 8, 8, 384)     1152        conv2d_177[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchNo (None, 8, 8, 384)     1152        conv2d_178[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)              (None, 8, 8, 192)     245760      average_pooling2d_17[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchNo (None, 8, 8, 320)     960         conv2d_171[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_173 (Activation)      (None, 8, 8, 384)     0           batch_normalization_173[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_174 (Activation)      (None, 8, 8, 384)     0           batch_normalization_174[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_177 (Activation)      (None, 8, 8, 384)     0           batch_normalization_177[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_178 (Activation)      (None, 8, 8, 384)     0           batch_normalization_178[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchNo (None, 8, 8, 192)     576         conv2d_179[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_171 (Activation)      (None, 8, 8, 320)     0           batch_normalization_171[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, 8, 8, 768)     0           activation_173[0][0]             \n",
      "                                                                   activation_174[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 8, 8, 768)     0           activation_177[0][0]             \n",
      "                                                                   activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_179 (Activation)      (None, 8, 8, 192)     0           batch_normalization_179[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, 8, 8, 2048)    0           activation_171[0][0]             \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_3[0][0]              \n",
      "                                                                   activation_179[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)              (None, 8, 8, 448)     917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchNo (None, 8, 8, 448)     1344        conv2d_184[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_184 (Activation)      (None, 8, 8, 448)     0           batch_normalization_184[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)              (None, 8, 8, 384)     786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)              (None, 8, 8, 384)     1548288     activation_184[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchNo (None, 8, 8, 384)     1152        conv2d_181[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchNo (None, 8, 8, 384)     1152        conv2d_185[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_181 (Activation)      (None, 8, 8, 384)     0           batch_normalization_181[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_185 (Activation)      (None, 8, 8, 384)     0           batch_normalization_185[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)              (None, 8, 8, 384)     442368      activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)              (None, 8, 8, 384)     442368      activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)              (None, 8, 8, 384)     442368      activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)              (None, 8, 8, 384)     442368      activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePoo (None, 8, 8, 2048)    0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)              (None, 8, 8, 320)     655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchNo (None, 8, 8, 384)     1152        conv2d_182[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchNo (None, 8, 8, 384)     1152        conv2d_183[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchNo (None, 8, 8, 384)     1152        conv2d_186[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchNo (None, 8, 8, 384)     1152        conv2d_187[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)              (None, 8, 8, 192)     393216      average_pooling2d_18[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchNo (None, 8, 8, 320)     960         conv2d_180[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_182 (Activation)      (None, 8, 8, 384)     0           batch_normalization_182[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_183 (Activation)      (None, 8, 8, 384)     0           batch_normalization_183[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_186 (Activation)      (None, 8, 8, 384)     0           batch_normalization_186[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_187 (Activation)      (None, 8, 8, 384)     0           batch_normalization_187[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchNo (None, 8, 8, 192)     576         conv2d_188[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_180 (Activation)      (None, 8, 8, 320)     0           batch_normalization_180[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, 8, 8, 768)     0           activation_182[0][0]             \n",
      "                                                                   activation_183[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 8, 8, 768)     0           activation_186[0][0]             \n",
      "                                                                   activation_187[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_188 (Activation)      (None, 8, 8, 192)     0           batch_normalization_188[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, 8, 8, 2048)    0           activation_180[0][0]             \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_4[0][0]              \n",
      "                                                                   activation_188[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2D (None, 2048)          0           mixed10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 2048)          0           avg_pool[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2048)          4196352     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 121)           247929      dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 26,247,065\n",
      "Trainable params: 26,212,633\n",
      "Non-trainable params: 34,432\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled\n",
      "Model created\n",
      "Loading training data...\n",
      "Loaded training data 3033/3033   \n",
      "Elapsed Time: Loading training\n",
      "0:00:11.083854\n",
      "Loading validation data...\n",
      "Loaded validation data516/1516   \n",
      "Elapsed Time: Loading validation\n",
      "0:00:05.098559\n",
      "Train on 3033 samples, validate on 1516 samples\n",
      "Epoch 1/100\n",
      "3033/3033 [==============================] - 50s - loss: 4.8168 - acc: 0.0059 - val_loss: 4.7594 - val_acc: 0.0020\n",
      "Epoch 2/100\n",
      "3033/3033 [==============================] - 42s - loss: 4.5541 - acc: 0.0712 - val_loss: 4.5585 - val_acc: 0.0864\n",
      "Epoch 3/100\n",
      "3033/3033 [==============================] - 43s - loss: 4.3161 - acc: 0.1213 - val_loss: 4.3405 - val_acc: 0.1135\n",
      "Epoch 4/100\n",
      "3033/3033 [==============================] - 43s - loss: 4.1058 - acc: 0.1259 - val_loss: 4.0971 - val_acc: 0.1372\n",
      "Epoch 5/100\n",
      "3033/3033 [==============================] - 43s - loss: 3.9444 - acc: 0.1560 - val_loss: 3.9734 - val_acc: 0.1577\n",
      "Epoch 6/100\n",
      "3033/3033 [==============================] - 43s - loss: 3.8180 - acc: 0.1863 - val_loss: 3.8605 - val_acc: 0.1788\n",
      "Epoch 7/100\n",
      "3033/3033 [==============================] - 43s - loss: 3.7020 - acc: 0.2015 - val_loss: 3.8428 - val_acc: 0.1985\n",
      "Epoch 8/100\n",
      "3033/3033 [==============================] - 43s - loss: 3.5884 - acc: 0.2311 - val_loss: 3.6703 - val_acc: 0.2216\n",
      "Epoch 9/100\n",
      "3033/3033 [==============================] - 43s - loss: 3.4708 - acc: 0.2661 - val_loss: 3.6345 - val_acc: 0.2322\n",
      "Epoch 10/100\n",
      "3033/3033 [==============================] - 43s - loss: 3.3592 - acc: 0.3023 - val_loss: 3.4895 - val_acc: 0.2810\n",
      "Epoch 11/100\n",
      "3033/3033 [==============================] - 43s - loss: 3.2553 - acc: 0.3122 - val_loss: 3.3644 - val_acc: 0.3054\n",
      "Epoch 12/100\n",
      "3033/3033 [==============================] - 43s - loss: 3.1416 - acc: 0.3465 - val_loss: 3.2598 - val_acc: 0.3206\n",
      "Epoch 13/100\n",
      "3033/3033 [==============================] - 43s - loss: 3.0320 - acc: 0.3778 - val_loss: 3.6904 - val_acc: 0.2500\n",
      "Epoch 14/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.9288 - acc: 0.3920 - val_loss: 3.3147 - val_acc: 0.3239\n",
      "Epoch 15/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.8334 - acc: 0.4187 - val_loss: 3.0553 - val_acc: 0.3661\n",
      "Epoch 16/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.7510 - acc: 0.4322 - val_loss: 2.9437 - val_acc: 0.3780\n",
      "Epoch 17/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.6638 - acc: 0.4448 - val_loss: 2.8593 - val_acc: 0.3872\n",
      "Epoch 18/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.5915 - acc: 0.4636 - val_loss: 2.8037 - val_acc: 0.3997\n",
      "Epoch 19/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.5128 - acc: 0.4735 - val_loss: 2.7928 - val_acc: 0.4037\n",
      "Epoch 20/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.4524 - acc: 0.4794 - val_loss: 2.7313 - val_acc: 0.4103\n",
      "Epoch 21/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.3949 - acc: 0.4962 - val_loss: 2.6629 - val_acc: 0.4222\n",
      "Epoch 22/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.3314 - acc: 0.5045 - val_loss: 2.6121 - val_acc: 0.4261\n",
      "Epoch 23/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.2779 - acc: 0.5236 - val_loss: 2.5869 - val_acc: 0.4347\n",
      "Epoch 24/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.2362 - acc: 0.5209 - val_loss: 2.5512 - val_acc: 0.4453\n",
      "Epoch 25/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.1882 - acc: 0.5318 - val_loss: 2.5164 - val_acc: 0.4518\n",
      "Epoch 26/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.1335 - acc: 0.5414 - val_loss: 2.4651 - val_acc: 0.4584\n",
      "Epoch 27/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.0804 - acc: 0.5612 - val_loss: 2.4698 - val_acc: 0.4532\n",
      "Epoch 28/100\n",
      "3033/3033 [==============================] - 42s - loss: 2.0392 - acc: 0.5648 - val_loss: 2.3952 - val_acc: 0.4703\n",
      "Epoch 29/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.9914 - acc: 0.5724 - val_loss: 2.3875 - val_acc: 0.4769\n",
      "Epoch 30/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.9564 - acc: 0.5833 - val_loss: 2.3425 - val_acc: 0.4756\n",
      "Epoch 31/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.8950 - acc: 0.5968 - val_loss: 2.3348 - val_acc: 0.4677\n",
      "Epoch 32/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.8621 - acc: 0.6040 - val_loss: 2.3213 - val_acc: 0.4763\n",
      "Epoch 33/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.8317 - acc: 0.6070 - val_loss: 2.2692 - val_acc: 0.4901\n",
      "Epoch 34/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.7935 - acc: 0.6172 - val_loss: 2.2353 - val_acc: 0.4914\n",
      "Epoch 35/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.7526 - acc: 0.6202 - val_loss: 2.2787 - val_acc: 0.4908\n",
      "Epoch 36/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.7181 - acc: 0.6291 - val_loss: 2.1995 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.6750 - acc: 0.6436 - val_loss: 2.1809 - val_acc: 0.5099\n",
      "Epoch 38/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.6427 - acc: 0.6495 - val_loss: 2.1703 - val_acc: 0.5073\n",
      "Epoch 39/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.6121 - acc: 0.6505 - val_loss: 2.1434 - val_acc: 0.5172\n",
      "Epoch 40/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.5874 - acc: 0.6551 - val_loss: 2.1363 - val_acc: 0.5198\n",
      "Epoch 41/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.5671 - acc: 0.6574 - val_loss: 2.1078 - val_acc: 0.5237\n",
      "Epoch 42/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.5258 - acc: 0.6667 - val_loss: 2.1030 - val_acc: 0.5198\n",
      "Epoch 43/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.4999 - acc: 0.6756 - val_loss: 2.0809 - val_acc: 0.5224\n",
      "Epoch 44/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.4699 - acc: 0.6762 - val_loss: 2.0649 - val_acc: 0.5218\n",
      "Epoch 45/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.4469 - acc: 0.6832 - val_loss: 2.0386 - val_acc: 0.5323\n",
      "Epoch 46/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.4084 - acc: 0.6930 - val_loss: 2.0445 - val_acc: 0.5251\n",
      "Epoch 47/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.3825 - acc: 0.6983 - val_loss: 2.0239 - val_acc: 0.5290\n",
      "Epoch 48/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.3593 - acc: 0.7000 - val_loss: 2.0161 - val_acc: 0.5297\n",
      "Epoch 49/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.3364 - acc: 0.7039 - val_loss: 2.0094 - val_acc: 0.5343\n",
      "Epoch 50/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.3061 - acc: 0.7145 - val_loss: 1.9766 - val_acc: 0.5343\n",
      "Epoch 51/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.2725 - acc: 0.7178 - val_loss: 1.9826 - val_acc: 0.5409\n",
      "Epoch 52/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.2502 - acc: 0.7263 - val_loss: 1.9509 - val_acc: 0.5356\n",
      "Epoch 53/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.2358 - acc: 0.7290 - val_loss: 1.9471 - val_acc: 0.5402\n",
      "Epoch 54/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.2084 - acc: 0.7405 - val_loss: 1.9475 - val_acc: 0.5449\n",
      "Epoch 55/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.1792 - acc: 0.7432 - val_loss: 1.9273 - val_acc: 0.5475\n",
      "Epoch 56/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.1560 - acc: 0.7451 - val_loss: 1.9206 - val_acc: 0.5449\n",
      "Epoch 57/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.1550 - acc: 0.7507 - val_loss: 1.9159 - val_acc: 0.5422\n",
      "Epoch 58/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.1114 - acc: 0.7636 - val_loss: 1.8931 - val_acc: 0.5449\n",
      "Epoch 59/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.0964 - acc: 0.7672 - val_loss: 1.8761 - val_acc: 0.5515\n",
      "Epoch 60/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.0689 - acc: 0.7751 - val_loss: 1.8808 - val_acc: 0.5475\n",
      "Epoch 61/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.0561 - acc: 0.7755 - val_loss: 1.8648 - val_acc: 0.5594\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3033/3033 [==============================] - 42s - loss: 1.0379 - acc: 0.7824 - val_loss: 1.8577 - val_acc: 0.5567\n",
      "Epoch 63/100\n",
      "3033/3033 [==============================] - 42s - loss: 1.0129 - acc: 0.7877 - val_loss: 1.8364 - val_acc: 0.5567\n",
      "Epoch 64/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.9946 - acc: 0.7939 - val_loss: 1.8378 - val_acc: 0.5554\n",
      "Epoch 65/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.9810 - acc: 0.7946 - val_loss: 1.8449 - val_acc: 0.5515\n",
      "Epoch 66/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.9596 - acc: 0.8022 - val_loss: 1.8389 - val_acc: 0.5627\n",
      "Epoch 67/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.9450 - acc: 0.8071 - val_loss: 1.8258 - val_acc: 0.5660\n",
      "Epoch 68/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.9261 - acc: 0.8084 - val_loss: 1.8250 - val_acc: 0.5613\n",
      "Epoch 69/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.9047 - acc: 0.8137 - val_loss: 1.8026 - val_acc: 0.5660\n",
      "Epoch 70/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.8946 - acc: 0.8167 - val_loss: 1.8127 - val_acc: 0.5587\n",
      "Epoch 71/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.8797 - acc: 0.8200 - val_loss: 1.7975 - val_acc: 0.5660\n",
      "Epoch 72/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.8596 - acc: 0.8259 - val_loss: 1.7804 - val_acc: 0.5699\n",
      "Epoch 73/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.8402 - acc: 0.8335 - val_loss: 1.7775 - val_acc: 0.5699\n",
      "Epoch 74/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.8236 - acc: 0.8371 - val_loss: 1.7734 - val_acc: 0.5726\n",
      "Epoch 75/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.8022 - acc: 0.8457 - val_loss: 1.7623 - val_acc: 0.5712\n",
      "Epoch 76/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.8003 - acc: 0.8427 - val_loss: 1.7755 - val_acc: 0.5706\n",
      "Epoch 77/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.7821 - acc: 0.8460 - val_loss: 1.7610 - val_acc: 0.5745\n",
      "Epoch 78/100\n",
      "3033/3033 [==============================] - 43s - loss: 0.7694 - acc: 0.8490 - val_loss: 1.7430 - val_acc: 0.5811\n",
      "Epoch 79/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.7543 - acc: 0.8589 - val_loss: 1.7665 - val_acc: 0.5765\n",
      "Epoch 80/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.7417 - acc: 0.8592 - val_loss: 1.7270 - val_acc: 0.5831\n",
      "Epoch 81/100\n",
      "3033/3033 [==============================] - 43s - loss: 0.7189 - acc: 0.8632 - val_loss: 1.7247 - val_acc: 0.5798\n",
      "Epoch 82/100\n",
      "3033/3033 [==============================] - 43s - loss: 0.7129 - acc: 0.8645 - val_loss: 1.7231 - val_acc: 0.5884\n",
      "Epoch 83/100\n",
      "3033/3033 [==============================] - 43s - loss: 0.7039 - acc: 0.8694 - val_loss: 1.7253 - val_acc: 0.5805\n",
      "Epoch 84/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.6881 - acc: 0.8747 - val_loss: 1.7346 - val_acc: 0.5785\n",
      "Epoch 85/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.6908 - acc: 0.8737 - val_loss: 1.7286 - val_acc: 0.5778\n",
      "Epoch 86/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.6719 - acc: 0.8731 - val_loss: 1.7299 - val_acc: 0.5765\n",
      "Epoch 87/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.6550 - acc: 0.8800 - val_loss: 1.7103 - val_acc: 0.5851\n",
      "Epoch 88/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.6446 - acc: 0.8830 - val_loss: 1.7054 - val_acc: 0.5838\n",
      "Epoch 89/100\n",
      "3033/3033 [==============================] - 43s - loss: 0.6248 - acc: 0.8879 - val_loss: 1.7308 - val_acc: 0.5811\n",
      "Epoch 90/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.6175 - acc: 0.8872 - val_loss: 1.7027 - val_acc: 0.5765\n",
      "Epoch 91/100\n",
      "3033/3033 [==============================] - 43s - loss: 0.6294 - acc: 0.8866 - val_loss: 1.7367 - val_acc: 0.5745\n",
      "Epoch 92/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.6134 - acc: 0.8919 - val_loss: 1.7011 - val_acc: 0.5818\n",
      "Epoch 93/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.5837 - acc: 0.8965 - val_loss: 1.6899 - val_acc: 0.5904\n",
      "Epoch 94/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.5811 - acc: 0.8955 - val_loss: 1.6714 - val_acc: 0.5891\n",
      "Epoch 95/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.5713 - acc: 0.8958 - val_loss: 1.6617 - val_acc: 0.5897\n",
      "Epoch 96/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.5524 - acc: 0.9054 - val_loss: 1.6623 - val_acc: 0.5910\n",
      "Epoch 97/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.5508 - acc: 0.9011 - val_loss: 1.6651 - val_acc: 0.5917\n",
      "Epoch 98/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.5389 - acc: 0.9041 - val_loss: 1.6662 - val_acc: 0.5877\n",
      "Epoch 99/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.5259 - acc: 0.9087 - val_loss: 1.6573 - val_acc: 0.5871\n",
      "Epoch 100/100\n",
      "3033/3033 [==============================] - 42s - loss: 0.5163 - acc: 0.9126 - val_loss: 1.6564 - val_acc: 0.5950\n",
      "Elapsed Time: Training\n",
      "1:11:24.014365\n",
      "{'acc': [0.0059347179682389213, 0.07121661677588105, 0.12133201450463219, 0.12594790628472846, 0.15595120326436238, 0.18628420693289513, 0.20145070841710952, 0.23112430017929128, 0.26607319618800351, 0.30234091832344578, 0.31223211475539592, 0.34652159567166979, 0.37784371890331547, 0.39202110160312909, 0.41872733322417738, 0.43224530260514948, 0.44477414898144463, 0.46356742239768772, 0.47345862076536405, 0.47939333861077771, 0.4962083738981361, 0.50445103597177199, 0.52357402167774603, 0.52093636485518613, 0.53181668539232752, 0.54137817505677066, 0.5611605667218964, 0.56478733840336159, 0.57237058991926792, 0.58325091095753645, 0.59676887953277469, 0.60402242187379884, 0.60698978267327575, 0.61721068632472986, 0.62017804466770143, 0.62908012608353003, 0.64358721243600192, 0.64952193077271658, 0.65051104933603188, 0.6551269387554266, 0.6574348903433388, 0.66666667148141712, 0.6755687444075632, 0.67622816146029285, 0.68315200181908231, 0.69304319379984491, 0.69831849899458642, 0.69996703219343015, 0.70392351190995905, 0.71447412178848901, 0.71777118358759839, 0.72634355747931634, 0.7289812093986916, 0.74052093821392573, 0.74315858981886829, 0.74513682533403136, 0.75074184037182456, 0.76360039478318353, 0.76722716581613126, 0.77514012194764603, 0.77546982917697604, 0.78239366395458543, 0.78766896850080959, 0.79393339538354113, 0.79459281178775343, 0.80217605874438591, 0.80712166227132542, 0.80844048069445484, 0.81371578687179846, 0.81668314802501207, 0.81998021473713212, 0.82591492847526893, 0.83349818460940528, 0.83712494970743623, 0.84569732391358676, 0.84272996639600095, 0.84602702819511044, 0.84899439031127422, 0.8588855852594951, 0.85921529476846203, 0.86317176972919674, 0.86449060224284047, 0.86943620020825207, 0.87471150178701773, 0.87372238371500355, 0.87306296892225876, 0.87998680601880919, 0.8829541638508277, 0.88789976739741927, 0.8872403539017093, 0.88658094140825361, 0.89185624202406921, 0.89647213863611142, 0.89548301759663884, 0.89581272451153615, 0.90537421122817285, 0.9010880293721929, 0.90405538492457449, 0.90867128023958188, 0.91262775979889454], 'loss': [4.8167535522138962, 4.5541273826739985, 4.316052920426074, 4.1058167922312068, 3.9443509030019808, 3.8180431053263497, 3.701956688591328, 3.5884277870896386, 3.4707505912856225, 3.359194584109781, 3.2553281277034922, 3.1415909576290244, 3.031956122804309, 2.928847428638472, 2.8334285678385589, 2.7510282982311507, 2.6638478006500637, 2.5914701753585518, 2.5127809278806992, 2.4524401054105622, 2.3949276325610698, 2.3313855319144188, 2.2779388335369775, 2.2362079627436064, 2.1881834032352394, 2.1335249245068519, 2.0803938836812423, 2.039207406221661, 1.9914306764983125, 1.9564426424791819, 1.8949528618531772, 1.8621453827770873, 1.8316986162278113, 1.7935184620411688, 1.7526150899793385, 1.7180781876573143, 1.6749573365477812, 1.6426615475271937, 1.6120979488387266, 1.5874257777887251, 1.567086855963516, 1.5258318399620496, 1.4999479032215253, 1.4698822823366315, 1.4469343772863659, 1.4083525430554806, 1.3825323107688292, 1.3592569447176865, 1.3363971154838359, 1.3060619709242542, 1.2724835985452869, 1.2501986591170575, 1.2357936057956393, 1.2084130683905843, 1.1791569408001068, 1.1559542307867847, 1.1550444696274207, 1.1113767695041761, 1.0963705563128603, 1.0688855117828666, 1.0560802409957826, 1.0378919427559159, 1.0128916894253668, 0.99459215995701789, 0.98097134041306688, 0.95963272492641116, 0.94495818271442011, 0.92613257152822759, 0.90473906214859001, 0.8945545228919769, 0.87971213679088844, 0.85960326985168334, 0.84020355863615193, 0.82355633068509204, 0.80218261598243679, 0.8002576388190219, 0.78208130879092441, 0.76936476070653714, 0.75433329711682007, 0.74173763747109933, 0.71893491803558207, 0.71291524533426809, 0.70392798878279528, 0.68806555080130827, 0.69081650032212627, 0.67186764308103741, 0.65501342142449726, 0.64458480026318699, 0.62480375668886978, 0.61745490699249883, 0.62940067746558281, 0.61344434742954279, 0.58367872287289291, 0.58114677301107209, 0.5713106216356143, 0.55236988411734211, 0.55075354632905238, 0.53890086830821793, 0.52586886023398161, 0.51627250996863849], 'val_acc': [0.001978891776348796, 0.086411608702510523, 0.11345646380985003, 0.13720316587797413, 0.15765171473978534, 0.17875989331890851, 0.19854881059093338, 0.22163588463237857, 0.23218997336904418, 0.28100263991818264, 0.30540897156600899, 0.32058047432462272, 0.24999999961665878, 0.32387862708370413, 0.36609498779031407, 0.37796834016852771, 0.38720316638418112, 0.39973614874018215, 0.40369393155568506, 0.41029023758496963, 0.422163587289624, 0.42612137144190654, 0.43469656901655224, 0.4452506588442659, 0.45184696711462219, 0.45844326787542228, 0.45316622608727075, 0.47031662088270865, 0.47691292718721257, 0.47559366561963878, 0.46767810034248636, 0.476253297917132, 0.49010553987485439, 0.49142480179628156, 0.49076517181849416, 0.50000000330263206, 0.50989445788407384, 0.5072559336873661, 0.51715039318343892, 0.51978891506044089, 0.52374669948794284, 0.51978891667243987, 0.52242743658358948, 0.5217678085716545, 0.53232189706258848, 0.52506596239229619, 0.5290237494147233, 0.52968337349495342, 0.53430078727117003, 0.53430079906628436, 0.54089709849030487, 0.53562005803893298, 0.54023746261496031, 0.54485487933995547, 0.54749340318280981, 0.54485488264258741, 0.54221635879973307, 0.54485488130580784, 0.55145119028387091, 0.54749340613158837, 0.55936675296609828, 0.55672823368402147, 0.55672823368402147, 0.55540897077966811, 0.55145119189586989, 0.56266491036459132, 0.56596305927060209, 0.56134564746023796, 0.56596306418523312, 0.55870712558323599, 0.56596306221938075, 0.56992084994951464, 0.56992084932044185, 0.57255936824866527, 0.57124010597338459, 0.57058047599559725, 0.57453826175987877, 0.58113456546945752, 0.57651715562494577, 0.58311345835159822, 0.57981530551388272, 0.58839050407145455, 0.58047493352581769, 0.57849604492923512, 0.57783641066588953, 0.5765171526761671, 0.58509235123373904, 0.58377309029523805, 0.58113456743530989, 0.57651715464201958, 0.57453825881110021, 0.58179419643017105, 0.59036939597066918, 0.58905013699802056, 0.5897097679587342, 0.59102902791430889, 0.5916886539603915, 0.58773087212781483, 0.58707124903051078, 0.59498681072981185], 'val_loss': [4.7593605738516533, 4.5584530213891989, 4.3404687256171393, 4.0970835805253802, 3.9733503053559476, 3.8604934938979336, 3.8428316355380661, 3.6703168782835585, 3.6344883357000226, 3.4895396198005977, 3.3643511055641877, 3.2597777922109437, 3.6903855096067164, 3.3147099197382661, 3.0552906147093761, 2.9437433732845539, 2.8593380998495701, 2.8037350498592004, 2.7928437689678023, 2.7312804828533084, 2.6628726780571847, 2.6120917142852944, 2.5869110102389294, 2.5511514750508333, 2.5164051103088663, 2.4651027142529753, 2.4697669867160768, 2.3951980422857884, 2.3875016750949669, 2.3425436169302243, 2.3347811459865921, 2.3213274293335888, 2.2691648393318959, 2.2352538572766849, 2.2787104423568243, 2.1994780464033967, 2.1808713056481293, 2.1703076672428203, 2.143369442869302, 2.1362953104255697, 2.1077737566034522, 2.1029555431142017, 2.0809105434958726, 2.0649177276364732, 2.038600904016822, 2.0445421934127808, 2.0238747911277106, 2.016125452078112, 2.0093874091523305, 1.9765981267498791, 1.982583325582318, 1.9509281404414718, 1.9471010433652469, 1.9474953395710142, 1.9273125765191534, 1.9206384410958806, 1.9159269693029901, 1.8931185713229519, 1.8760652548404986, 1.8808385762816053, 1.8648163553592711, 1.8577048229667945, 1.8364180867464373, 1.8377999263891758, 1.8448964132482584, 1.8388627783289686, 1.8257770856011826, 1.8250106005366684, 1.8025925010049564, 1.812717872118887, 1.7974523615711282, 1.7804428617369217, 1.7774948037394118, 1.7734280113809027, 1.7623105258299996, 1.7755064105610106, 1.7610273510610837, 1.7430439600843868, 1.7665216715165997, 1.7269890712559381, 1.7247292995452881, 1.7231408854587726, 1.7253441708383586, 1.7346145804765043, 1.7285737253745188, 1.7298561114434516, 1.7102773779300398, 1.7054433671654372, 1.7307650141791493, 1.7026684883402017, 1.7367472911258486, 1.7010858077801627, 1.6899102234274228, 1.6713659544733395, 1.6616719899831787, 1.662272700376435, 1.6650658444867599, 1.6661525832631656, 1.6573465320239911, 1.6563977297189054]}\n",
      "Model weights saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing data...\n",
      "Loaded testing data  25785/25785   \n",
      "Elapsed Time: Loading testing\n",
      "0:01:30.988596\n",
      "25785/25785 [==============================] - 116s   \n",
      "Elapsed Time: Testing\n",
      "0:01:56.695611\n",
      "[1.6212889593147322, 0.60783401562165729]\n",
      "['loss', 'acc']\n"
     ]
    }
   ],
   "source": [
    "description = \"\"\"Inception V3 - +0 inception + 2048 dense (extended) output\"\"\"\n",
    "logger(\"-----------------------------------------------------------------\")\n",
    "logger(ID)\n",
    "logger(description)\n",
    "\n",
    "# Make model\n",
    "model = load_model()\n",
    "print(\"Model created\")\n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Load the training data\n",
    "X_train, Y_train = cal.load_training()\n",
    "\n",
    "# Print time loading training\n",
    "elapsed_time = datetime.now() - start_time\n",
    "logger(\"Elapsed Time: Loading training\")\n",
    "logger(elapsed_time)   \n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Load the validation data\n",
    "X_val, Y_val = cal.load_validation()\n",
    "\n",
    "# Print time loading validation\n",
    "elapsed_time = datetime.now() - start_time\n",
    "logger(\"Elapsed Time: Loading validation\")\n",
    "logger(elapsed_time)  \n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Train model and store stats in history\n",
    "history = model.fit(x=X_train,y=Y_train,batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,validation_data=(X_val,Y_val))\n",
    "\n",
    "history = history.history\n",
    "\n",
    "# Print total time\n",
    "elapsed_time = datetime.now() - start_time\n",
    "logger(\"Elapsed Time: Training\")\n",
    "logger(elapsed_time)   \n",
    "\n",
    "# Save model weights\n",
    "model_dir = 'models'\n",
    "\n",
    "model_name = '{}'.format(ID)\n",
    "model_name += '.h5'\n",
    "model_path = os.path.join(model_dir,model_name)\n",
    "\n",
    "model.save(model_path)\n",
    "\n",
    "logger(history)\n",
    "print(\"Model weights saved\")\n",
    "\n",
    "accuracy = {'Training': history['acc'],\n",
    "            'Validation': history['val_acc']}\n",
    "\n",
    "loss = {'Training': history['loss'],\n",
    "        'Validation': history['val_loss']}\n",
    "\n",
    "# Plot training vs validation accuracy  \n",
    "plot(accuracy, \"Accuracy: Training vs Validation\",\n",
    "        'Epochs', 'Accuracy', '{}_accuracy_train_val'.format(ID))\n",
    "\n",
    "# Plot training vs validation loss  \n",
    "plot(loss, \"Loss: Training vs Validation\",\n",
    "        'Epochs', 'Loss', '{}_loss_train_val'.format(ID))\n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Loading testing data\n",
    "X_test, Y_test = cal.load_testing()\n",
    "\n",
    "# Print time loading testing\n",
    "elapsed_time = datetime.now() - start_time\n",
    "logger(\"Elapsed Time: Loading testing\")\n",
    "logger(elapsed_time)  \n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Test model\n",
    "metrics = model.evaluate(x=X_test,y=Y_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Print time testing\n",
    "elapsed_time = datetime.now() - start_time\n",
    "logger(\"Elapsed Time: Testing\")\n",
    "logger(elapsed_time)  \n",
    "\n",
    "logger(metrics)\n",
    "logger(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
